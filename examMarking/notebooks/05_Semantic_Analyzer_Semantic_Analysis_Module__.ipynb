{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "328c6407",
   "metadata": {},
   "source": [
    "# Semantic Analysis Module   - Detailed Walkthrough\n",
    "\n",
    "## Purpose\n",
    "\n",
    "Calculates semantic similarity using sentence transformer embeddings.\n",
    "Captures conceptual understanding beyond keyword matching.\n",
    "\n",
    "## Why This Module Exists\n",
    "\n",
    "**Why semantic analysis:**\n",
    "- Students might paraphrase correctly without using exact keywords\n",
    "- Conceptual understanding > rote memorization\n",
    "- Handles synonyms and related concepts automatically\n",
    "- More aligned with how humans grade answers\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "**Technology:**\n",
    "- Model: all-MiniLM-L6-v2 (384-dim embeddings, 80MB, fast)\n",
    "- Alternative: all-mpnet-base-v2 (768-dim, 420MB, more accurate)\n",
    "\n",
    "**Algorithm:**\n",
    "1. Generate embeddings for student answer sentences\n",
    "2. Generate embeddings for model answer sentences\n",
    "3. Calculate cosine similarity matrix\n",
    "4. Find best matches for each model sentence\n",
    "5. Aggregate scores (mean of maximum similarities)\n",
    "\n",
    "**Output**: Similarity score from 0 (completely different) to 1 (identical meaning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d47d753",
   "metadata": {},
   "source": [
    "## Complete Source Code\n",
    "\n",
    "Below is the full implementation with inline documentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd507a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Semantic Analyzer Module\n",
    "Calculates semantic similarity using sentence transformers\n",
    "\"\"\"\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from typing import List, Dict\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class SemanticAnalyzer:\n",
    "    \"\"\"Analyze semantic similarity between texts\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name=\"all-MiniLM-L6-v2\"):\n",
    "        \"\"\"\n",
    "        Initialize semantic analyzer\n",
    "        \n",
    "        Args:\n",
    "            model_name: Sentence transformer model name\n",
    "        \"\"\"\n",
    "        try:\n",
    "            logger.info(f\"Loading sentence transformer model: {model_name}\")\n",
    "            self.model = SentenceTransformer(model_name)\n",
    "            self.model_name = model_name\n",
    "            logger.info(f\"Model loaded successfully\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading model: {e}\")\n",
    "            self.model = None\n",
    "    \n",
    "    def get_embedding(self, text: str) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Get embedding vector for text\n",
    "        \n",
    "        Args:\n",
    "            text: Input text\n",
    "            \n",
    "        Returns:\n",
    "            Embedding vector\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise RuntimeError(\"Model not loaded\")\n",
    "        \n",
    "        return self.model.encode(text, convert_to_numpy=True)\n",
    "    \n",
    "    def get_embeddings(self, texts: List[str]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Get embedding vectors for multiple texts\n",
    "        \n",
    "        Args:\n",
    "            texts: List of input texts\n",
    "            \n",
    "        Returns:\n",
    "            Array of embedding vectors\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise RuntimeError(\"Model not loaded\")\n",
    "        \n",
    "        return self.model.encode(texts, convert_to_numpy=True)\n",
    "    \n",
    "    def calculate_similarity(self, text1: str, text2: str) -> float:\n",
    "        \"\"\"\n",
    "        Calculate cosine similarity between two texts\n",
    "        \n",
    "        Args:\n",
    "            text1: First text\n",
    "            text2: Second text\n",
    "            \n",
    "        Returns:\n",
    "            Similarity score (0-1)\n",
    "        \"\"\"\n",
    "        emb1 = self.get_embedding(text1)\n",
    "        emb2 = self.get_embedding(text2)\n",
    "        \n",
    "        # Reshape for sklearn\n",
    "        emb1 = emb1.reshape(1, -1)\n",
    "        emb2 = emb2.reshape(1, -1)\n",
    "        \n",
    "        similarity = cosine_similarity(emb1, emb2)[0][0]\n",
    "        return float(similarity)\n",
    "    \n",
    "    def calculate_sentence_similarities(self, student_text: str, \n",
    "                                       model_text: str) -> Dict:\n",
    "        \"\"\"\n",
    "        Calculate similarity between sentences of two texts\n",
    "        \n",
    "        Args:\n",
    "            student_text: Student's answer\n",
    "            model_text: Model answer\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with similarity analysis\n",
    "        \"\"\"\n",
    "        # Split into sentences (simple approach)\n",
    "        student_sentences = [s.strip() for s in student_text.split('.') if s.strip()]\n",
    "        model_sentences = [s.strip() for s in model_text.split('.') if s.strip()]\n",
    "        \n",
    "        if not student_sentences or not model_sentences:\n",
    "            return {\n",
    "                \"overall_similarity\": 0.0,\n",
    "                \"max_similarity\": 0.0,\n",
    "                \"mean_similarity\": 0.0,\n",
    "                \"sentence_matches\": []\n",
    "            }\n",
    "        \n",
    "        # Get embeddings\n",
    "        student_embeddings = self.get_embeddings(student_sentences)\n",
    "        model_embeddings = self.get_embeddings(model_sentences)\n",
    "        \n",
    "        # Calculate similarity matrix\n",
    "        similarity_matrix = cosine_similarity(student_embeddings, model_embeddings)\n",
    "        \n",
    "        # Find best match for each model sentence\n",
    "        sentence_matches = []\n",
    "        for i, model_sent in enumerate(model_sentences):\n",
    "            best_match_idx = np.argmax(similarity_matrix[:, i])\n",
    "            best_similarity = similarity_matrix[best_match_idx, i]\n",
    "            sentence_matches.append({\n",
    "                \"model_sentence\": model_sent[:100],  # Truncate for display\n",
    "                \"student_sentence\": student_sentences[best_match_idx][:100],\n",
    "                \"similarity\": float(best_similarity)\n",
    "            })\n",
    "        \n",
    "        # Calculate aggregate scores\n",
    "        max_similarities = np.max(similarity_matrix, axis=0)\n",
    "        \n",
    "        return {\n",
    "            \"overall_similarity\": float(np.mean(max_similarities)),\n",
    "            \"max_similarity\": float(np.max(max_similarities)),\n",
    "            \"min_similarity\": float(np.min(max_similarities)),\n",
    "            \"mean_similarity\": float(np.mean(max_similarities)),\n",
    "            \"sentence_matches\": sentence_matches,\n",
    "            \"coverage\": float(np.sum(max_similarities > 0.5) / len(model_sentences))\n",
    "        }\n",
    "    \n",
    "    def evaluate_answer(self, student_answer: str, \n",
    "                       model_answer: str,\n",
    "                       threshold=0.5) -> Dict:\n",
    "        \"\"\"\n",
    "        Comprehensive semantic evaluation\n",
    "        \n",
    "        Args:\n",
    "            student_answer: Student's answer\n",
    "            model_answer: Model answer\n",
    "            threshold: Minimum similarity for partial credit\n",
    "            \n",
    "        Returns:\n",
    "            Evaluation results\n",
    "        \"\"\"\n",
    "        # Overall similarity\n",
    "        overall_sim = self.calculate_similarity(student_answer, model_answer)\n",
    "        \n",
    "        # Sentence-level analysis\n",
    "        sentence_analysis = self.calculate_sentence_similarities(student_answer, model_answer)\n",
    "        \n",
    "        # Determine score\n",
    "        if overall_sim >= 0.9:\n",
    "            score = 1.0\n",
    "            grade = \"Excellent\"\n",
    "        elif overall_sim >= 0.75:\n",
    "            score = 0.85\n",
    "            grade = \"Good\"\n",
    "        elif overall_sim >= threshold:\n",
    "            score = 0.6\n",
    "            grade = \"Adequate\"\n",
    "        elif overall_sim >= threshold * 0.7:\n",
    "            score = 0.4\n",
    "            grade = \"Poor\"\n",
    "        else:\n",
    "            score = 0.2\n",
    "            grade = \"Very Poor\"\n",
    "        \n",
    "        return {\n",
    "            \"semantic_score\": score,\n",
    "            \"overall_similarity\": overall_sim,\n",
    "            \"grade\": grade,\n",
    "            \"sentence_analysis\": sentence_analysis,\n",
    "            \"passed_threshold\": overall_sim >= threshold\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d339f409",
   "metadata": {},
   "source": [
    "## Testing the Module\n",
    "\n",
    "Let's test this module to see it in action:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec98a590",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_analyzer import SemanticAnalyzer\n",
    "\n",
    "print(\"Loading semantic model (may take a moment)...\")\n",
    "analyzer = SemanticAnalyzer()\n",
    "\n",
    "text1 = \"Binary search tree is a data structure\"\n",
    "text2 = \"BST is a hierarchical data structure\"\n",
    "\n",
    "similarity = analyzer.calculate_similarity(text1, text2)\n",
    "print(f\"Similarity between texts: {similarity:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ca8d1e",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This module is a critical component of the AI-based answer evaluation system. It provides:\n",
    "\n",
    "- **Semantic Analysis Module  ** functionality\n",
    "- Clear, well-documented code\n",
    "- Error handling and robustness\n",
    "- Integration with other system modules\n",
    "\n",
    "**Next Steps**: Explore other module notebooks to understand the complete system!\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
