{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "310297bf",
   "metadata": {},
   "source": [
    "# Configuration Module - Detailed Walkthrough\n",
    "\n",
    "## Purpose\n",
    "\n",
    "This module serves as the central configuration hub for the entire evaluation system.\n",
    "It defines all configurable parameters including paths, model selections, evaluation weights, and thresholds.\n",
    "\n",
    "## Why This Module Exists\n",
    "\n",
    "**Why centralize configuration?**\n",
    "- Easy to modify settings without changing core logic\n",
    "- Maintain consistency across modules\n",
    "- Support different deployment environments\n",
    "- Enable easy testing with various configurations\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "**Key Configuration Areas:**\n",
    "1. **Directory Paths**: Project structure and file locations\n",
    "2. **NLP Models**: spaCy and sentence transformer model selection\n",
    "3. **Evaluation Weights**: 60% semantic, 25% keyword, 15% concept\n",
    "4. **Thresholds**: Cutoff values for similarity and matching\n",
    "5. **Penalties**: Rules for mark deductions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca88e2d",
   "metadata": {},
   "source": [
    "## Complete Source Code\n",
    "\n",
    "Below is the full implementation with inline documentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05dd649",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Configuration Management for Answer Evaluation System\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "class Config:\n",
    "    \"\"\"Central configuration for the evaluation system\"\"\"\n",
    "    \n",
    "    # Project Paths\n",
    "    BASE_DIR = Path(__file__).parent.parent\n",
    "    DATA_DIR = BASE_DIR / \"data\"\n",
    "    OUTPUT_DIR = BASE_DIR / \"output\"\n",
    "    MODEL_ANSWERS_DIR = DATA_DIR / \"model_answers\"\n",
    "    KNOWLEDGE_BASE_PATH = DATA_DIR / \"knowledge_base.json\"\n",
    "    \n",
    "    # NLP Models\n",
    "    SPACY_MODEL = \"en_core_web_sm\"\n",
    "    SENTENCE_TRANSFORMER_MODEL = \"all-MiniLM-L6-v2\"  # Fast and efficient\n",
    "    # Alternative: \"all-mpnet-base-v2\" for better accuracy\n",
    "    \n",
    "    # Evaluation Weights\n",
    "    SEMANTIC_WEIGHT = 0.60  # 60% weight to semantic similarity\n",
    "    KEYWORD_WEIGHT = 0.25   # 25% weight to keyword matching\n",
    "    CONCEPT_WEIGHT = 0.15   # 15% weight to concept coverage\n",
    "    \n",
    "    # Thresholds\n",
    "    SEMANTIC_SIMILARITY_THRESHOLD = 0.5  # Minimum similarity for partial credit\n",
    "    KEYWORD_MATCH_THRESHOLD = 0.80  # Fuzzy matching threshold\n",
    "    CONCEPT_COVERAGE_THRESHOLD = 0.70  # Minimum for concept detection\n",
    "    \n",
    "    # Marking Scheme\n",
    "    PENALTY_MISSING_CRITICAL_CONCEPT = 0.20  # Deduct 20% per missing critical concept\n",
    "    PARTIAL_CREDIT_MIN = 0.30  # Minimum 30% for attempting the question\n",
    "    \n",
    "    # Performance Analysis\n",
    "    STRONG_PERFORMANCE_THRESHOLD = 80  # Above 80% is strong\n",
    "    WEAK_PERFORMANCE_THRESHOLD = 60  # Below 60% needs improvement\n",
    "    \n",
    "    # Output\n",
    "    OUTPUT_FORMAT = \"json\"  # Options: json, csv, pdf\n",
    "    VERBOSE_FEEDBACK = True\n",
    "    \n",
    "    @classmethod\n",
    "    def ensure_directories(cls):\n",
    "        \"\"\"Create necessary directories if they don't exist\"\"\"\n",
    "        cls.DATA_DIR.mkdir(exist_ok=True)\n",
    "        cls.OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "        cls.MODEL_ANSWERS_DIR.mkdir(exist_ok=True)\n",
    "    \n",
    "    @classmethod\n",
    "    def update_weights(cls, semantic=None, keyword=None, concept=None):\n",
    "        \"\"\"Update evaluation weights\"\"\"\n",
    "        if semantic is not None:\n",
    "            cls.SEMANTIC_WEIGHT = semantic\n",
    "        if keyword is not None:\n",
    "            cls.KEYWORD_WEIGHT = keyword\n",
    "        if concept is not None:\n",
    "            cls.CONCEPT_WEIGHT = concept\n",
    "        \n",
    "        # Normalize to sum to 1.0\n",
    "        total = cls.SEMANTIC_WEIGHT + cls.KEYWORD_WEIGHT + cls.CONCEPT_WEIGHT\n",
    "        cls.SEMANTIC_WEIGHT /= total\n",
    "        cls.KEYWORD_WEIGHT /= total\n",
    "        cls.CONCEPT_WEIGHT /= total\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4698c2",
   "metadata": {},
   "source": [
    "## Testing the Module\n",
    "\n",
    "Let's test this module to see it in action:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18d6804",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import Config\n",
    "\n",
    "print(\"Configuration Settings:\")\n",
    "print(f\"Semantic Weight: {Config.SEMANTIC_WEIGHT}\")\n",
    "print(f\"Keyword Weight: {Config.KEYWORD_WEIGHT}\")\n",
    "print(f\"Concept Weight: {Config.CONCEPT_WEIGHT}\")\n",
    "print(f\"Transformer Model: {Config.SENTENCE_TRANSFORMER_MODEL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffaca889",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This module is a critical component of the AI-based answer evaluation system. It provides:\n",
    "\n",
    "- **Configuration Module** functionality\n",
    "- Clear, well-documented code\n",
    "- Error handling and robustness\n",
    "- Integration with other system modules\n",
    "\n",
    "**Next Steps**: Explore other module notebooks to understand the complete system!\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
