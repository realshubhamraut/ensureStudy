{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b45b90e4",
   "metadata": {},
   "source": [
    "# Feedback Generation Module - Detailed Walkthrough\n",
    "\n",
    "## Purpose\n",
    "\n",
    "Generates constructive, human-readable feedback explaining scores.\n",
    "Helps students understand what they did well and where to improve.\n",
    "\n",
    "## Why This Module Exists\n",
    "\n",
    "**Why detailed feedback matters:**\n",
    "- Students learn from mistakes\n",
    "- Transparent grading builds trust\n",
    "- Actionable suggestions guide future study\n",
    "- Reduces teacher workload in explaining marks\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "**Feedback Components:**\n",
    "1. **Summary**: Marks, percentage, grade (A-F)\n",
    "2. **Strengths**: What was covered well\n",
    "3. **Weaknesses**: Missing concepts and keywords\n",
    "4. **Mark Deductions**: Explanation for each deduction\n",
    "5. **Recommendations**: Specific topics to study\n",
    "\n",
    "**Grade Thresholds:**\n",
    "- 90%+ : Excellent\n",
    "- 80-89%: Very Good\n",
    "- 70-79%: Good\n",
    "- 60-69%: Satisfactory\n",
    "- 50-59%: Pass\n",
    "- <50%: Needs Improvement\n",
    "\n",
    "**Personalization**: Feedback adapts based on specific gaps detected.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d95a0b",
   "metadata": {},
   "source": [
    "## Complete Source Code\n",
    "\n",
    "Below is the full implementation with inline documentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cb5f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Feedback Generator Module\n",
    "Generates constructive feedback for students\n",
    "\"\"\"\n",
    "\n",
    "from typing import Dict, List\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class FeedbackGenerator:\n",
    "    \"\"\"Generate human-readable feedback from evaluation results\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.grade_thresholds = {\n",
    "            90: (\"Excellent\", \"Outstanding understanding\"),\n",
    "            80: (\"Very Good\", \"Strong grasp of concepts\"),\n",
    "            70: (\"Good\", \"Good understanding with minor gaps\"),\n",
    "            60: (\"Satisfactory\", \"Adequate understanding\"),\n",
    "            50: (\"Pass\", \"Basic understanding demonstrated\"),\n",
    "            40: (\"Weak\", \"Significant gaps in understanding\"),\n",
    "            0: (\"Poor\", \"Major concepts missing\")\n",
    "        }\n",
    "    \n",
    "    def get_grade(self, percentage: float) -> tuple:\n",
    "        \"\"\"\n",
    "        Get grade and description based on percentage\n",
    "        \n",
    "        Args:\n",
    "            percentage: Score percentage (0-100)\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (grade, description)\n",
    "        \"\"\"\n",
    "        for threshold in sorted(self.grade_thresholds.keys(), reverse=True):\n",
    "            if percentage >= threshold:\n",
    "                return self.grade_thresholds[threshold]\n",
    "        return (\"Fail\", \"Needs significant improvement\")\n",
    "    \n",
    "    def generate_feedback(self, evaluation_result: Dict, verbose=True) -> Dict:\n",
    "        \"\"\"\n",
    "        Generate comprehensive feedback\n",
    "        \n",
    "        Args:\n",
    "            evaluation_result: Results from EvaluationEngine\n",
    "            verbose: Include detailed analysis if True\n",
    "            \n",
    "        Returns:\n",
    "            Feedback dictionary\n",
    "        \"\"\"\n",
    "        marks = evaluation_result[\"marks_obtained\"]\n",
    "        max_marks = evaluation_result[\"max_marks\"]\n",
    "        percentage = evaluation_result[\"percentage\"]\n",
    "        scores = evaluation_result[\"scores\"]\n",
    "        \n",
    "        grade, grade_desc = self.get_grade(percentage)\n",
    "        \n",
    "        # Strengths and weaknesses\n",
    "        strengths = []\n",
    "        weaknesses = []\n",
    "        suggestions = []\n",
    "        \n",
    "        # Analyze semantic performance\n",
    "        semantic_details = scores[\"semantic\"][\"details\"]\n",
    "        if scores[\"semantic\"][\"score\"] >= 0.75:\n",
    "            strengths.append(\"Good semantic understanding of the topic\")\n",
    "        elif scores[\"semantic\"][\"score\"] < 0.5:\n",
    "            weaknesses.append(\"Conceptual understanding needs improvement\")\n",
    "            suggestions.append(\"Review the core concepts and their relationships\")\n",
    "        \n",
    "        # Analyze keyword coverage\n",
    "        keyword_details = scores[\"keyword\"][\"details\"]\n",
    "        matched_kws = keyword_details.get(\"matched_keywords\", [])\n",
    "        missed_kws = keyword_details.get(\"missed_keywords\", [])\n",
    "        \n",
    "        if scores[\"keyword\"][\"score\"] >= 0.7:\n",
    "            strengths.append(f\"Good coverage of key terms ({len(matched_kws)} key terms mentioned)\")\n",
    "        else:\n",
    "            weaknesses.append(f\"Missing important keywords: {', '.join(missed_kws[:5])}\")\n",
    "            if missed_kws:\n",
    "                suggestions.append(f\"Include key terms like: {', '.join(missed_kws[:3])}\")\n",
    "        \n",
    "        # Analyze concept coverage\n",
    "        concept_details = scores[\"concept\"].get(\"details\", {})\n",
    "        if concept_details:\n",
    "            detected = concept_details.get(\"detected_concepts\", [])\n",
    "            missing = concept_details.get(\"missing_concepts\", [])\n",
    "            critical_missing = concept_details.get(\"critical_concepts_missing\", [])\n",
    "            \n",
    "            if detected:\n",
    "                detected_names = [c[\"concept\"] for c in detected]\n",
    "                strengths.append(f\"Covered concepts: {', '.join(detected_names)}\")\n",
    "            \n",
    "            if critical_missing:\n",
    "                critical_names = [c[\"concept\"] for c in critical_missing]\n",
    "                weaknesses.append(f\"Missing critical concepts: {', '.join(critical_names)}\")\n",
    "                suggestions.append(f\"Study these important topics: {', '.join(critical_names)}\")\n",
    "            elif missing:\n",
    "                missing_names = [c[\"concept\"] for c in missing[:3]]\n",
    "                weaknesses.append(f\"Some concepts not covered: {', '.join(missing_names)}\")\n",
    "        \n",
    "        # Mark deduction explanation\n",
    "        marks_lost = max_marks - marks\n",
    "        deductions = []\n",
    "        \n",
    "        if scores[\"semantic\"][\"score\"] < 1.0:\n",
    "            semantic_loss = (1 - scores[\"semantic\"][\"score\"]) * scores[\"semantic\"][\"weight\"] * max_marks\n",
    "            deductions.append({\n",
    "                \"reason\": \"Semantic similarity below expected level\",\n",
    "                \"marks_deducted\": round(semantic_loss, 2)\n",
    "            })\n",
    "        \n",
    "        if scores[\"keyword\"][\"score\"] < 1.0:\n",
    "            keyword_loss = (1 - scores[\"keyword\"][\"score\"]) * scores[\"keyword\"][\"weight\"] * max_marks\n",
    "            deductions.append({\n",
    "                \"reason\": f\"Missing key terms: {', '.join(missed_kws[:3])}\",\n",
    "                \"marks_deducted\": round(keyword_loss, 2)\n",
    "            })\n",
    "        \n",
    "        if concept_details and concept_details.get(\"missing_concepts\"):\n",
    "            concept_loss = (1 - scores[\"concept\"][\"score\"]) * scores[\"concept\"][\"weight\"] * max_marks\n",
    "            deductions.append({\n",
    "                \"reason\": \"Incomplete concept coverage\",\n",
    "                \"marks_deducted\": round(concept_loss, 2)\n",
    "            })\n",
    "        \n",
    "        # Build feedback\n",
    "        feedback = {\n",
    "            \"summary\": {\n",
    "                \"marks_obtained\": round(marks, 2),\n",
    "                \"max_marks\": max_marks,\n",
    "                \"percentage\": round(percentage, 1),\n",
    "                \"grade\": grade,\n",
    "                \"grade_description\": grade_desc\n",
    "            },\n",
    "            \"strengths\": strengths if strengths else [\"Answer demonstrates basic attempt\"],\n",
    "            \"weaknesses\": weaknesses if weaknesses else [\"No major weaknesses identified\"],\n",
    "            \"suggestions\": suggestions if suggestions else [\"Continue with good work\"],\n",
    "            \"deductions\": deductions,\n",
    "            \"detailed_scores\": {\n",
    "                \"semantic_similarity\": f\"{scores['semantic']['score']*100:.1f}%\",\n",
    "                \"keyword_matching\": f\"{scores['keyword']['score']*100:.1f}%\",\n",
    "                \"concept_coverage\": f\"{scores['concept']['score']*100:.1f}%\"\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        if verbose:\n",
    "            feedback[\"verbose_analysis\"] = {\n",
    "                \"semantic_details\": semantic_details,\n",
    "                \"keyword_match_details\": keyword_details,\n",
    "                \"concept_detection\": concept_details\n",
    "            }\n",
    "        \n",
    "        return feedback\n",
    "    \n",
    "    def format_feedback_text(self, feedback: Dict) -> str:\n",
    "        \"\"\"\n",
    "        Format feedback as readable text\n",
    "        \n",
    "        Args:\n",
    "            feedback: Feedback dictionary\n",
    "            \n",
    "        Returns:\n",
    "            Formatted text string\n",
    "        \"\"\"\n",
    "        summary = feedback[\"summary\"]\n",
    "        \n",
    "        text = f\"\"\"\n",
    "{'='*70}\n",
    "EVALUATION FEEDBACK\n",
    "{'='*70}\n",
    "\n",
    "SCORE: {summary['marks_obtained']}/{summary['max_marks']} ({summary['percentage']}%)\n",
    "GRADE: {summary['grade']} - {summary['grade_description']}\n",
    "\n",
    "{'='*70}\n",
    "STRENGTHS:\n",
    "{'='*70}\n",
    "\"\"\"\n",
    "        for i, strength in enumerate(feedback[\"strengths\"], 1):\n",
    "            text += f\"  ✓ {strength}\\n\"\n",
    "        \n",
    "        text += f\"\"\"\n",
    "{'='*70}\n",
    "AREAS FOR IMPROVEMENT:\n",
    "{'='*70}\n",
    "\"\"\"\n",
    "        for i, weakness in enumerate(feedback[\"weaknesses\"], 1):\n",
    "            text += f\"  ✗ {weakness}\\n\"\n",
    "        \n",
    "        text += f\"\"\"\n",
    "{'='*70}\n",
    "MARK DEDUCTIONS:\n",
    "{'='*70}\n",
    "\"\"\"\n",
    "        for deduction in feedback[\"deductions\"]:\n",
    "            text += f\"  - {deduction['reason']}: -{deduction['marks_deducted']} marks\\n\"\n",
    "        \n",
    "        text += f\"\"\"\n",
    "{'='*70}\n",
    "RECOMMENDATIONS:\n",
    "{'='*70}\n",
    "\"\"\"\n",
    "        for i, suggestion in enumerate(feedback[\"suggestions\"], 1):\n",
    "            text += f\"  {i}. {suggestion}\\n\"\n",
    "        \n",
    "        text += f\"\"\"\n",
    "{'='*70}\n",
    "DETAILED BREAKDOWN:\n",
    "{'='*70}\n",
    "  • Semantic Similarity: {feedback['detailed_scores']['semantic_similarity']}\n",
    "  • Keyword Matching: {feedback['detailed_scores']['keyword_matching']}\n",
    "  • Concept Coverage: {feedback['detailed_scores']['concept_coverage']}\n",
    "{'='*70}\n",
    "\"\"\"\n",
    "        \n",
    "        return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6972bb4",
   "metadata": {},
   "source": [
    "## Testing the Module\n",
    "\n",
    "Let's test this module to see it in action:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b045ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feedback_generator import FeedbackGenerator\n",
    "\n",
    "feedback_gen = FeedbackGenerator()\n",
    "grade, desc = feedback_gen.get_grade(75)\n",
    "print(f\"75% → Grade: {grade}, Description: {desc}\")\n",
    "\n",
    "grade, desc = feedback_gen.get_grade(92)\n",
    "print(f\"92% → Grade: {grade}, Description: {desc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dcfee0",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This module is a critical component of the AI-based answer evaluation system. It provides:\n",
    "\n",
    "- **Feedback Generation Module** functionality\n",
    "- Clear, well-documented code\n",
    "- Error handling and robustness\n",
    "- Integration with other system modules\n",
    "\n",
    "**Next Steps**: Explore other module notebooks to understand the complete system!\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
