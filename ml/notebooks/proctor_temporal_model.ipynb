{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üß† Temporal LSTM Proctoring Model Training\n",
                "\n",
                "Train an LSTM model for temporal behavior analysis - detecting cheating patterns over sequences of frames.\n",
                "\n",
                "**Based on**: AutoOEP/Temporal/temporal_trainer.py\n",
                "\n",
                "## Why Temporal Analysis?\n",
                "\n",
                "Static models analyze individual frames, but cheating behavior often involves patterns:\n",
                "- Frequent looking away then back\n",
                "- Gradual head movements toward notes\n",
                "- Suspicious hand movements over time\n",
                "\n",
                "The LSTM learns these temporal patterns from sequences of features."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "import json\n",
                "from datetime import datetime\n",
                "from collections import deque\n",
                "\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.metrics import (\n",
                "    accuracy_score, precision_score, recall_score, f1_score,\n",
                "    roc_auc_score, confusion_matrix, classification_report\n",
                ")\n",
                "\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# Check for GPU\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f\"Using device: {device}\")\n",
                "print(\"‚úÖ Libraries imported\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Paths\n",
                "BASE_PATH = os.path.dirname(os.getcwd())  # ml/ directory\n",
                "DATA_PATH = os.path.join(BASE_PATH, 'data', 'proctoring')\n",
                "MODEL_PATH = os.path.join(BASE_PATH, 'models', 'proctoring')\n",
                "\n",
                "os.makedirs(MODEL_PATH, exist_ok=True)\n",
                "\n",
                "# Training configuration\n",
                "CONFIG = {\n",
                "    # Data\n",
                "    'window_size': 15,       # Number of frames in each sequence\n",
                "    'overlap': 5,            # Overlap between sequences\n",
                "    'test_size': 0.2,\n",
                "    \n",
                "    # Model\n",
                "    'model_type': 'lstm',    # 'lstm' or 'gru'\n",
                "    'hidden_size': 128,\n",
                "    'num_layers': 2,\n",
                "    'dropout': 0.3,\n",
                "    \n",
                "    # Training\n",
                "    'epochs': 80,\n",
                "    'batch_size': 32,\n",
                "    'learning_rate': 0.001,\n",
                "    'early_stopping_patience': 15,\n",
                "    \n",
                "    # Inference\n",
                "    'threshold': 0.4,\n",
                "    'random_state': 42\n",
                "}\n",
                "\n",
                "# Feature columns (must match static model)\n",
                "FEATURE_COLUMNS = [\n",
                "    'verification_result', 'num_faces', 'iris_pos', 'iris_ratio',\n",
                "    'mouth_zone', 'mouth_area', 'x_rotation', 'y_rotation', 'z_rotation',\n",
                "    'radial_distance', 'gaze_direction', 'gaze_zone',\n",
                "    'watch', 'headphone', 'closedbook', 'earpiece', 'cell phone',\n",
                "    'openbook', 'chits', 'sheet', 'H-Distance', 'F-Distance'\n",
                "]\n",
                "\n",
                "print(f\"Window size: {CONFIG['window_size']} frames\")\n",
                "print(f\"Features: {len(FEATURE_COLUMNS)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Model Definition"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class LSTMModel(nn.Module):\n",
                "    \"\"\"LSTM model for temporal cheating detection.\"\"\"\n",
                "    \n",
                "    def __init__(self, input_size, hidden_size=128, num_layers=2, dropout=0.3):\n",
                "        super(LSTMModel, self).__init__()\n",
                "        \n",
                "        self.hidden_size = hidden_size\n",
                "        self.num_layers = num_layers\n",
                "        \n",
                "        self.lstm = nn.LSTM(\n",
                "            input_size=input_size,\n",
                "            hidden_size=hidden_size,\n",
                "            num_layers=num_layers,\n",
                "            batch_first=True,\n",
                "            dropout=dropout if num_layers > 1 else 0\n",
                "        )\n",
                "        \n",
                "        self.dropout = nn.Dropout(dropout)\n",
                "        self.fc = nn.Linear(hidden_size, 1)\n",
                "        self.sigmoid = nn.Sigmoid()\n",
                "    \n",
                "    def forward(self, x):\n",
                "        # x: (batch, seq_len, features)\n",
                "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
                "        # Use last hidden state\n",
                "        last_hidden = lstm_out[:, -1, :]\n",
                "        out = self.dropout(last_hidden)\n",
                "        out = self.fc(out)\n",
                "        return self.sigmoid(out).squeeze(-1)\n",
                "\n",
                "\n",
                "class GRUModel(nn.Module):\n",
                "    \"\"\"GRU model (alternative to LSTM).\"\"\"\n",
                "    \n",
                "    def __init__(self, input_size, hidden_size=128, num_layers=2, dropout=0.3):\n",
                "        super(GRUModel, self).__init__()\n",
                "        \n",
                "        self.hidden_size = hidden_size\n",
                "        self.num_layers = num_layers\n",
                "        \n",
                "        self.gru = nn.GRU(\n",
                "            input_size=input_size,\n",
                "            hidden_size=hidden_size,\n",
                "            num_layers=num_layers,\n",
                "            batch_first=True,\n",
                "            dropout=dropout if num_layers > 1 else 0\n",
                "        )\n",
                "        \n",
                "        self.dropout = nn.Dropout(dropout)\n",
                "        self.fc = nn.Linear(hidden_size, 1)\n",
                "        self.sigmoid = nn.Sigmoid()\n",
                "    \n",
                "    def forward(self, x):\n",
                "        gru_out, h_n = self.gru(x)\n",
                "        last_hidden = gru_out[:, -1, :]\n",
                "        out = self.dropout(last_hidden)\n",
                "        out = self.fc(out)\n",
                "        return self.sigmoid(out).squeeze(-1)\n",
                "\n",
                "\n",
                "print(\"‚úÖ Model classes defined\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Data Preparation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class SequenceDataset(Dataset):\n",
                "    \"\"\"PyTorch Dataset for sequences.\"\"\"\n",
                "    \n",
                "    def __init__(self, sequences, labels):\n",
                "        self.sequences = torch.FloatTensor(sequences)\n",
                "        self.labels = torch.FloatTensor(labels)\n",
                "    \n",
                "    def __len__(self):\n",
                "        return len(self.sequences)\n",
                "    \n",
                "    def __getitem__(self, idx):\n",
                "        return self.sequences[idx], self.labels[idx]\n",
                "\n",
                "\n",
                "def create_sequences(df, feature_columns, window_size, overlap):\n",
                "    \"\"\"Create sliding window sequences from dataframe.\"\"\"\n",
                "    sequences = []\n",
                "    labels = []\n",
                "    \n",
                "    # Group by video to maintain temporal continuity\n",
                "    if 'video' in df.columns:\n",
                "        groups = df.groupby('video')\n",
                "    else:\n",
                "        groups = [('all', df)]\n",
                "    \n",
                "    step = window_size - overlap\n",
                "    \n",
                "    for video_name, video_df in groups:\n",
                "        video_df = video_df.sort_values('timestamp') if 'timestamp' in video_df.columns else video_df\n",
                "        features = video_df[feature_columns].values\n",
                "        targets = video_df['is_cheating'].values\n",
                "        \n",
                "        for i in range(0, len(features) - window_size + 1, step):\n",
                "            seq = features[i:i + window_size]\n",
                "            # Label is 1 if any frame in window is cheating\n",
                "            label = 1 if np.any(targets[i:i + window_size] == 1) else 0\n",
                "            \n",
                "            sequences.append(seq)\n",
                "            labels.append(label)\n",
                "    \n",
                "    return np.array(sequences), np.array(labels)\n",
                "\n",
                "\n",
                "def load_and_prepare_data(data_path, feature_columns, config):\n",
                "    \"\"\"Load data and create sequences.\"\"\"\n",
                "    \n",
                "    # Load CSVs\n",
                "    csv_files = [f for f in os.listdir(data_path) if f.endswith('.csv')]\n",
                "    if not csv_files:\n",
                "        print(f\"‚ùå No CSV files in {data_path}\")\n",
                "        return None, None, None, None, None\n",
                "    \n",
                "    dfs = [pd.read_csv(os.path.join(data_path, f)) for f in csv_files]\n",
                "    combined_df = pd.concat(dfs, ignore_index=True)\n",
                "    \n",
                "    print(f\"Total rows: {len(combined_df)}\")\n",
                "    \n",
                "    # Filter to available features\n",
                "    available = [c for c in feature_columns if c in combined_df.columns]\n",
                "    combined_df = combined_df.fillna(0)\n",
                "    \n",
                "    # Split by video for train/test\n",
                "    if 'video' in combined_df.columns:\n",
                "        videos = combined_df['video'].unique()\n",
                "        np.random.seed(config['random_state'])\n",
                "        np.random.shuffle(videos)\n",
                "        split_idx = int(len(videos) * (1 - config['test_size']))\n",
                "        train_videos = videos[:split_idx]\n",
                "        test_videos = videos[split_idx:]\n",
                "        \n",
                "        train_df = combined_df[combined_df['video'].isin(train_videos)]\n",
                "        test_df = combined_df[combined_df['video'].isin(test_videos)]\n",
                "    else:\n",
                "        # Random split\n",
                "        train_df = combined_df.sample(frac=1-config['test_size'], random_state=config['random_state'])\n",
                "        test_df = combined_df.drop(train_df.index)\n",
                "    \n",
                "    print(f\"Train: {len(train_df)} rows, Test: {len(test_df)} rows\")\n",
                "    \n",
                "    # Create sequences\n",
                "    X_train, y_train = create_sequences(train_df, available, config['window_size'], config['overlap'])\n",
                "    X_test, y_test = create_sequences(test_df, available, config['window_size'], config['overlap'])\n",
                "    \n",
                "    print(f\"Train sequences: {len(X_train)}, Test sequences: {len(X_test)}\")\n",
                "    print(f\"Sequence shape: {X_train.shape}\")\n",
                "    \n",
                "    # Scale features\n",
                "    scaler = StandardScaler()\n",
                "    X_train_flat = X_train.reshape(-1, X_train.shape[-1])\n",
                "    scaler.fit(X_train_flat)\n",
                "    \n",
                "    X_train_scaled = scaler.transform(X_train_flat).reshape(X_train.shape)\n",
                "    X_test_flat = X_test.reshape(-1, X_test.shape[-1])\n",
                "    X_test_scaled = scaler.transform(X_test_flat).reshape(X_test.shape)\n",
                "    \n",
                "    return X_train_scaled, y_train, X_test_scaled, y_test, scaler\n",
                "\n",
                "\n",
                "# Load data\n",
                "X_train, y_train, X_test, y_test, scaler = load_and_prepare_data(\n",
                "    DATA_PATH, FEATURE_COLUMNS, CONFIG\n",
                ")\n",
                "\n",
                "if X_train is not None:\n",
                "    print(f\"\\nClass balance (train): {np.mean(y_train):.2%} positive\")\n",
                "    print(f\"Class balance (test): {np.mean(y_test):.2%} positive\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def train_model(model, train_loader, val_loader, config, device):\n",
                "    \"\"\"Train the LSTM model.\"\"\"\n",
                "    \n",
                "    criterion = nn.BCELoss()\n",
                "    optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
                "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5)\n",
                "    \n",
                "    history = {'train_loss': [], 'val_loss': [], 'val_auc': []}\n",
                "    best_val_loss = float('inf')\n",
                "    patience_counter = 0\n",
                "    best_model_state = None\n",
                "    \n",
                "    for epoch in range(config['epochs']):\n",
                "        # Training\n",
                "        model.train()\n",
                "        train_loss = 0.0\n",
                "        \n",
                "        for sequences, labels in train_loader:\n",
                "            sequences, labels = sequences.to(device), labels.to(device)\n",
                "            \n",
                "            optimizer.zero_grad()\n",
                "            outputs = model(sequences)\n",
                "            loss = criterion(outputs, labels)\n",
                "            loss.backward()\n",
                "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
                "            optimizer.step()\n",
                "            \n",
                "            train_loss += loss.item()\n",
                "        \n",
                "        train_loss /= len(train_loader)\n",
                "        \n",
                "        # Validation\n",
                "        model.eval()\n",
                "        val_loss = 0.0\n",
                "        all_preds = []\n",
                "        all_labels = []\n",
                "        \n",
                "        with torch.no_grad():\n",
                "            for sequences, labels in val_loader:\n",
                "                sequences, labels = sequences.to(device), labels.to(device)\n",
                "                outputs = model(sequences)\n",
                "                loss = criterion(outputs, labels)\n",
                "                val_loss += loss.item()\n",
                "                \n",
                "                all_preds.extend(outputs.cpu().numpy())\n",
                "                all_labels.extend(labels.cpu().numpy())\n",
                "        \n",
                "        val_loss /= len(val_loader)\n",
                "        val_auc = roc_auc_score(all_labels, all_preds)\n",
                "        \n",
                "        history['train_loss'].append(train_loss)\n",
                "        history['val_loss'].append(val_loss)\n",
                "        history['val_auc'].append(val_auc)\n",
                "        \n",
                "        scheduler.step(val_loss)\n",
                "        \n",
                "        # Early stopping\n",
                "        if val_loss < best_val_loss:\n",
                "            best_val_loss = val_loss\n",
                "            best_model_state = model.state_dict().copy()\n",
                "            patience_counter = 0\n",
                "        else:\n",
                "            patience_counter += 1\n",
                "        \n",
                "        if (epoch + 1) % 10 == 0:\n",
                "            print(f\"Epoch {epoch+1}/{config['epochs']} | \"\n",
                "                  f\"Train Loss: {train_loss:.4f} | \"\n",
                "                  f\"Val Loss: {val_loss:.4f} | \"\n",
                "                  f\"Val AUC: {val_auc:.4f}\")\n",
                "        \n",
                "        if patience_counter >= config['early_stopping_patience']:\n",
                "            print(f\"\\nEarly stopping at epoch {epoch+1}\")\n",
                "            break\n",
                "    \n",
                "    # Load best model\n",
                "    if best_model_state:\n",
                "        model.load_state_dict(best_model_state)\n",
                "    \n",
                "    return model, history"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if X_train is not None:\n",
                "    # Create DataLoaders\n",
                "    train_dataset = SequenceDataset(X_train, y_train)\n",
                "    test_dataset = SequenceDataset(X_test, y_test)\n",
                "    \n",
                "    train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'], shuffle=True)\n",
                "    test_loader = DataLoader(test_dataset, batch_size=CONFIG['batch_size'], shuffle=False)\n",
                "    \n",
                "    # Create model\n",
                "    input_size = X_train.shape[-1]\n",
                "    \n",
                "    if CONFIG['model_type'] == 'lstm':\n",
                "        model = LSTMModel(\n",
                "            input_size=input_size,\n",
                "            hidden_size=CONFIG['hidden_size'],\n",
                "            num_layers=CONFIG['num_layers'],\n",
                "            dropout=CONFIG['dropout']\n",
                "        ).to(device)\n",
                "    else:\n",
                "        model = GRUModel(\n",
                "            input_size=input_size,\n",
                "            hidden_size=CONFIG['hidden_size'],\n",
                "            num_layers=CONFIG['num_layers'],\n",
                "            dropout=CONFIG['dropout']\n",
                "        ).to(device)\n",
                "    \n",
                "    print(f\"Model: {CONFIG['model_type'].upper()}\")\n",
                "    print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
                "    \n",
                "    # Train\n",
                "    print(\"\\nTraining...\")\n",
                "    model, history = train_model(model, train_loader, test_loader, CONFIG, device)\n",
                "    print(\"\\n‚úÖ Training complete\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def evaluate_model(model, test_loader, threshold, device):\n",
                "    \"\"\"Evaluate model on test set.\"\"\"\n",
                "    model.eval()\n",
                "    all_preds = []\n",
                "    all_labels = []\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        for sequences, labels in test_loader:\n",
                "            sequences = sequences.to(device)\n",
                "            outputs = model(sequences)\n",
                "            all_preds.extend(outputs.cpu().numpy())\n",
                "            all_labels.extend(labels.numpy())\n",
                "    \n",
                "    y_pred = (np.array(all_preds) >= threshold).astype(int)\n",
                "    y_proba = np.array(all_preds)\n",
                "    y_true = np.array(all_labels)\n",
                "    \n",
                "    metrics = {\n",
                "        'accuracy': accuracy_score(y_true, y_pred),\n",
                "        'precision': precision_score(y_true, y_pred),\n",
                "        'recall': recall_score(y_true, y_pred),\n",
                "        'f1': f1_score(y_true, y_pred),\n",
                "        'auc_roc': roc_auc_score(y_true, y_proba)\n",
                "    }\n",
                "    \n",
                "    print(\"=\" * 50)\n",
                "    print(\"TEMPORAL MODEL EVALUATION\")\n",
                "    print(\"=\" * 50)\n",
                "    for name, value in metrics.items():\n",
                "        print(f\"{name.upper():15}: {value:.4f}\")\n",
                "    \n",
                "    print(\"\\nClassification Report:\")\n",
                "    print(classification_report(y_true, y_pred, target_names=['Not Cheating', 'Cheating']))\n",
                "    \n",
                "    return metrics, y_proba, y_true\n",
                "\n",
                "\n",
                "if X_train is not None:\n",
                "    metrics, y_proba, y_true = evaluate_model(model, test_loader, CONFIG['threshold'], device)\n",
                "    \n",
                "    # Plot training history\n",
                "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
                "    \n",
                "    axes[0].plot(history['train_loss'], label='Train')\n",
                "    axes[0].plot(history['val_loss'], label='Validation')\n",
                "    axes[0].set_xlabel('Epoch')\n",
                "    axes[0].set_ylabel('Loss')\n",
                "    axes[0].legend()\n",
                "    axes[0].set_title('Training Loss')\n",
                "    \n",
                "    axes[1].plot(history['val_auc'])\n",
                "    axes[1].set_xlabel('Epoch')\n",
                "    axes[1].set_ylabel('AUC-ROC')\n",
                "    axes[1].set_title('Validation AUC')\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Save Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def save_temporal_model(model, scaler, config, metrics, model_path):\n",
                "    \"\"\"Save LSTM model and metadata.\"\"\"\n",
                "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
                "    \n",
                "    # Save model with scaler\n",
                "    model_file = os.path.join(model_path, 'temporal_lstm.pt')\n",
                "    \n",
                "    save_dict = {\n",
                "        'model_state_dict': model.state_dict(),\n",
                "        'scaler_mean': scaler.mean_,\n",
                "        'scaler_scale': scaler.scale_,\n",
                "        'config': config,\n",
                "        'input_size': config.get('input_size', 22)\n",
                "    }\n",
                "    \n",
                "    torch.save(save_dict, model_file)\n",
                "    print(f\"‚úÖ Model saved: {model_file}\")\n",
                "    \n",
                "    # Save metadata\n",
                "    metadata = {\n",
                "        'model_type': config['model_type'],\n",
                "        'window_size': config['window_size'],\n",
                "        'hidden_size': config['hidden_size'],\n",
                "        'num_layers': config['num_layers'],\n",
                "        'threshold': config['threshold'],\n",
                "        'training_date': timestamp,\n",
                "        'metrics': {k: float(v) for k, v in metrics.items()}\n",
                "    }\n",
                "    \n",
                "    metadata_file = os.path.join(model_path, 'temporal_metadata.json')\n",
                "    with open(metadata_file, 'w') as f:\n",
                "        json.dump(metadata, f, indent=2)\n",
                "    print(f\"‚úÖ Metadata saved: {metadata_file}\")\n",
                "\n",
                "\n",
                "if X_train is not None:\n",
                "    CONFIG['input_size'] = X_train.shape[-1]\n",
                "    save_temporal_model(model, scaler, CONFIG, metrics, MODEL_PATH)\n",
                "    print(\"\\nüéâ Temporal model training complete!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Inference Example"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def predict_sequence(model, scaler, sequence, device, threshold=0.4):\n",
                "    \"\"\"\n",
                "    Predict cheating probability for a sequence of frames.\n",
                "    \n",
                "    Args:\n",
                "        model: Trained LSTM model\n",
                "        scaler: Fitted StandardScaler\n",
                "        sequence: numpy array of shape (window_size, num_features)\n",
                "        threshold: Classification threshold\n",
                "    \n",
                "    Returns:\n",
                "        probability: Cheating probability (0-1)\n",
                "        is_cheating: Boolean prediction\n",
                "    \"\"\"\n",
                "    model.eval()\n",
                "    \n",
                "    # Scale features\n",
                "    seq_scaled = scaler.transform(sequence)\n",
                "    seq_tensor = torch.FloatTensor(seq_scaled).unsqueeze(0).to(device)\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        prob = model(seq_tensor).item()\n",
                "    \n",
                "    return prob, prob >= threshold\n",
                "\n",
                "\n",
                "# Example usage\n",
                "if X_train is not None:\n",
                "    # Get a test sequence\n",
                "    test_seq = X_test[0]  # Already scaled\n",
                "    \n",
                "    # For demo, unscale it first\n",
                "    test_seq_unscaled = scaler.inverse_transform(test_seq)\n",
                "    \n",
                "    prob, is_cheating = predict_sequence(model, scaler, test_seq_unscaled, device)\n",
                "    print(f\"Cheating probability: {prob:.2%}\")\n",
                "    print(f\"Prediction: {'CHEATING' if is_cheating else 'NOT CHEATING'}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.14.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
