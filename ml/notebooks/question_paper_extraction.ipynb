{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸ“„ Question Paper Processing Pipeline\n",
                "\n",
                "This notebook extracts structured data from question papers:\n",
                "\n",
                "1. **Paper Metadata** - Title, subject, total marks, time limit\n",
                "2. **Question Extraction** - Question text, marks, number\n",
                "3. **Section Detection** - Group questions by section\n",
                "4. **Answer Key Association** - Link expected answers\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup & Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install dependencies if needed\n",
                "# !pip install pypdf2 pdf2image pytesseract pillow opencv-python"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import re\n",
                "import json\n",
                "from pathlib import Path\n",
                "from typing import List, Dict, Optional, Tuple\n",
                "from dataclasses import dataclass, field, asdict\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# PDF handling\n",
                "try:\n",
                "    from PyPDF2 import PdfReader\n",
                "    PDF_AVAILABLE = True\n",
                "except ImportError:\n",
                "    PDF_AVAILABLE = False\n",
                "    print(\"âš ï¸ PyPDF2 not installed. PDF support disabled.\")\n",
                "\n",
                "# OCR for scanned papers\n",
                "try:\n",
                "    import pytesseract\n",
                "    from PIL import Image\n",
                "    OCR_AVAILABLE = True\n",
                "except ImportError:\n",
                "    OCR_AVAILABLE = False\n",
                "    print(\"âš ï¸ pytesseract not installed. OCR support disabled.\")\n",
                "\n",
                "print(f\"PDF support: {PDF_AVAILABLE}\")\n",
                "print(f\"OCR support: {OCR_AVAILABLE}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 2. Data Structures"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "@dataclass\n",
                "class Question:\n",
                "    \"\"\"Represents a single question from a paper.\"\"\"\n",
                "    number: str  # e.g., \"1\", \"2a\", \"3.i\"\n",
                "    text: str\n",
                "    marks: float\n",
                "    section: Optional[str] = None  # e.g., \"Section A\", \"Part I\"\n",
                "    question_type: str = \"short_answer\"  # short_answer, long_answer, mcq, fill_blank\n",
                "    expected_answer: Optional[str] = None\n",
                "    keywords: List[str] = field(default_factory=list)\n",
                "    sub_questions: List['Question'] = field(default_factory=list)\n",
                "\n",
                "\n",
                "@dataclass\n",
                "class QuestionPaper:\n",
                "    \"\"\"Complete question paper structure.\"\"\"\n",
                "    title: str\n",
                "    subject: str\n",
                "    total_marks: float\n",
                "    time_limit_minutes: int\n",
                "    instructions: List[str] = field(default_factory=list)\n",
                "    sections: List[str] = field(default_factory=list)\n",
                "    questions: List[Question] = field(default_factory=list)\n",
                "    raw_text: str = \"\"\n",
                "    \n",
                "    def to_dict(self) -> dict:\n",
                "        \"\"\"Convert to dictionary for JSON serialization.\"\"\"\n",
                "        return {\n",
                "            \"title\": self.title,\n",
                "            \"subject\": self.subject,\n",
                "            \"total_marks\": self.total_marks,\n",
                "            \"time_limit_minutes\": self.time_limit_minutes,\n",
                "            \"instructions\": self.instructions,\n",
                "            \"sections\": self.sections,\n",
                "            \"questions\": [asdict(q) for q in self.questions],\n",
                "            \"question_count\": len(self.questions)\n",
                "        }\n",
                "\n",
                "\n",
                "# Example\n",
                "sample_question = Question(\n",
                "    number=\"1\",\n",
                "    text=\"State Newton's first law of motion.\",\n",
                "    marks=2.0,\n",
                "    section=\"Section A\",\n",
                "    question_type=\"short_answer\",\n",
                "    keywords=[\"rest\", \"motion\", \"external force\", \"inertia\"]\n",
                ")\n",
                "print(f\"Sample question: {sample_question.number} ({sample_question.marks} marks)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 3. Text Extraction (PDF & Image)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def extract_text_from_pdf(pdf_path: str) -> str:\n",
                "    \"\"\"\n",
                "    Extract text from a PDF file.\n",
                "    \"\"\"\n",
                "    if not PDF_AVAILABLE:\n",
                "        raise ImportError(\"PyPDF2 is required for PDF processing\")\n",
                "    \n",
                "    reader = PdfReader(pdf_path)\n",
                "    text_parts = []\n",
                "    \n",
                "    for page in reader.pages:\n",
                "        text = page.extract_text()\n",
                "        if text:\n",
                "            text_parts.append(text)\n",
                "    \n",
                "    return \"\\n\".join(text_parts)\n",
                "\n",
                "\n",
                "def extract_text_from_image(image_path: str) -> str:\n",
                "    \"\"\"\n",
                "    Extract text from an image using OCR.\n",
                "    \"\"\"\n",
                "    if not OCR_AVAILABLE:\n",
                "        raise ImportError(\"pytesseract is required for OCR\")\n",
                "    \n",
                "    image = Image.open(image_path)\n",
                "    text = pytesseract.image_to_string(image)\n",
                "    return text\n",
                "\n",
                "\n",
                "def extract_text(file_path: str) -> str:\n",
                "    \"\"\"\n",
                "    Extract text from any supported file type.\n",
                "    \"\"\"\n",
                "    path = Path(file_path)\n",
                "    suffix = path.suffix.lower()\n",
                "    \n",
                "    if suffix == '.pdf':\n",
                "        return extract_text_from_pdf(file_path)\n",
                "    elif suffix in ['.png', '.jpg', '.jpeg', '.webp', '.tiff']:\n",
                "        return extract_text_from_image(file_path)\n",
                "    elif suffix == '.txt':\n",
                "        return path.read_text()\n",
                "    else:\n",
                "        raise ValueError(f\"Unsupported file type: {suffix}\")\n",
                "\n",
                "\n",
                "print(\"âœ… Text extraction functions defined\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 4. Paper Metadata Extraction"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class MetadataExtractor:\n",
                "    \"\"\"\n",
                "    Extract paper metadata: title, subject, marks, time.\n",
                "    \"\"\"\n",
                "    \n",
                "    # Regex patterns for common formats\n",
                "    PATTERNS = {\n",
                "        'total_marks': [\n",
                "            r'total\\s*(?:marks?)?\\s*[:\\-]?\\s*(\\d+)',\n",
                "            r'maximum\\s*marks?\\s*[:\\-]?\\s*(\\d+)',\n",
                "            r'max\\.?\\s*marks?\\s*[:\\-]?\\s*(\\d+)',\n",
                "            r'(\\d+)\\s*marks?\\s*(?:total|maximum)',\n",
                "            r'marks?\\s*[:\\-]\\s*(\\d+)',\n",
                "        ],\n",
                "        'time_limit': [\n",
                "            r'time\\s*(?:allowed)?\\s*[:\\-]?\\s*(\\d+)\\s*(?:hours?|hrs?)',\n",
                "            r'time\\s*[:\\-]?\\s*(\\d+)\\s*(?:minutes?|mins?)',\n",
                "            r'duration\\s*[:\\-]?\\s*(\\d+)\\s*(?:hours?|hrs?)',\n",
                "            r'(\\d+)\\s*(?:hours?|hrs?)\\s*(?:allowed)?',\n",
                "        ],\n",
                "        'subject': [\n",
                "            r'subject\\s*[:\\-]?\\s*([A-Za-z\\s]+)',\n",
                "            r'(?:physics|chemistry|biology|mathematics|english|history|geography)',\n",
                "        ]\n",
                "    }\n",
                "    \n",
                "    SUBJECTS = ['physics', 'chemistry', 'biology', 'mathematics', 'math', \n",
                "                'english', 'history', 'geography', 'science', 'economics']\n",
                "    \n",
                "    @classmethod\n",
                "    def extract_total_marks(cls, text: str) -> float:\n",
                "        \"\"\"Extract total marks from paper text.\"\"\"\n",
                "        text_lower = text.lower()\n",
                "        \n",
                "        for pattern in cls.PATTERNS['total_marks']:\n",
                "            match = re.search(pattern, text_lower)\n",
                "            if match:\n",
                "                return float(match.group(1))\n",
                "        \n",
                "        return 0.0\n",
                "    \n",
                "    @classmethod\n",
                "    def extract_time_limit(cls, text: str) -> int:\n",
                "        \"\"\"Extract time limit in minutes.\"\"\"\n",
                "        text_lower = text.lower()\n",
                "        \n",
                "        for pattern in cls.PATTERNS['time_limit']:\n",
                "            match = re.search(pattern, text_lower)\n",
                "            if match:\n",
                "                value = int(match.group(1))\n",
                "                # Convert hours to minutes if needed\n",
                "                if 'hour' in pattern or 'hr' in pattern:\n",
                "                    return value * 60\n",
                "                return value\n",
                "        \n",
                "        return 0\n",
                "    \n",
                "    @classmethod\n",
                "    def extract_subject(cls, text: str) -> str:\n",
                "        \"\"\"Detect subject from text.\"\"\"\n",
                "        text_lower = text.lower()\n",
                "        \n",
                "        for subject in cls.SUBJECTS:\n",
                "            if subject in text_lower:\n",
                "                return subject.capitalize()\n",
                "        \n",
                "        return \"General\"\n",
                "    \n",
                "    @classmethod\n",
                "    def extract_title(cls, text: str) -> str:\n",
                "        \"\"\"Extract paper title from first few lines.\"\"\"\n",
                "        lines = text.strip().split('\\n')[:10]\n",
                "        \n",
                "        for line in lines:\n",
                "            line = line.strip()\n",
                "            # Look for exam-like titles\n",
                "            if any(keyword in line.lower() for keyword in \n",
                "                   ['exam', 'test', 'assessment', 'paper', 'quiz', 'midterm', 'final']):\n",
                "                return line[:100]  # Limit title length\n",
                "            # Or use first substantial line\n",
                "            if len(line) > 10 and not line.startswith(('1', '2', 'Q', 'q')):\n",
                "                return line[:100]\n",
                "        \n",
                "        return \"Question Paper\"\n",
                "\n",
                "\n",
                "# Test\n",
                "sample_text = \"\"\"\n",
                "PHYSICS EXAMINATION - Class XII\n",
                "Maximum Marks: 70\n",
                "Time Allowed: 3 Hours\n",
                "\n",
                "Instructions:\n",
                "1. All questions are compulsory\n",
                "2. Section A has 20 questions of 1 mark each\n",
                "\n",
                "Section A\n",
                "1. State Newton's first law of motion. (2 marks)\n",
                "\"\"\"\n",
                "\n",
                "print(f\"Title: {MetadataExtractor.extract_title(sample_text)}\")\n",
                "print(f\"Subject: {MetadataExtractor.extract_subject(sample_text)}\")\n",
                "print(f\"Total Marks: {MetadataExtractor.extract_total_marks(sample_text)}\")\n",
                "print(f\"Time: {MetadataExtractor.extract_time_limit(sample_text)} minutes\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 5. Question Extraction"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class QuestionExtractor:\n",
                "    \"\"\"\n",
                "    Extract individual questions from paper text.\n",
                "    \"\"\"\n",
                "    \n",
                "    # Patterns to identify question starts\n",
                "    QUESTION_PATTERNS = [\n",
                "        # \"1. Question text\" or \"1) Question text\"\n",
                "        r'^\\s*(\\d+)[.)]\\s+(.+?)(?=\\n\\s*\\d+[.)]|\\n\\s*(?:Section|SECTION)|$)',\n",
                "        # \"Q1. Question text\" or \"Q.1 Question text\"\n",
                "        r'^\\s*[Qq]\\.?\\s*(\\d+)[.)]?\\s+(.+?)(?=\\n\\s*[Qq]|\\n\\s*(?:Section|SECTION)|$)',\n",
                "        # \"(a) Sub question\"\n",
                "        r'^\\s*\\(([a-z])\\)\\s+(.+?)(?=\\n\\s*\\([a-z]\\)|$)',\n",
                "    ]\n",
                "    \n",
                "    # Patterns for marks\n",
                "    MARK_PATTERNS = [\n",
                "        r'\\((\\d+(?:\\.\\d+)?)\\s*(?:marks?|m)\\)',  # (2 marks) or (2m)\n",
                "        r'\\[(\\d+(?:\\.\\d+)?)\\s*(?:marks?|m)?\\]',  # [2] or [2 marks]\n",
                "        r'(\\d+(?:\\.\\d+)?)\\s*marks?$',  # 2 marks at end\n",
                "    ]\n",
                "    \n",
                "    # Section patterns\n",
                "    SECTION_PATTERNS = [\n",
                "        r'Section\\s+([A-Z])',\n",
                "        r'SECTION\\s+([A-Z])',\n",
                "        r'Part\\s+([IVX]+|\\d+)',\n",
                "    ]\n",
                "    \n",
                "    @classmethod\n",
                "    def extract_marks(cls, text: str) -> Tuple[str, float]:\n",
                "        \"\"\"\n",
                "        Extract marks from question text.\n",
                "        Returns (cleaned_text, marks)\n",
                "        \"\"\"\n",
                "        for pattern in cls.MARK_PATTERNS:\n",
                "            match = re.search(pattern, text, re.IGNORECASE)\n",
                "            if match:\n",
                "                marks = float(match.group(1))\n",
                "                cleaned = re.sub(pattern, '', text, flags=re.IGNORECASE).strip()\n",
                "                return cleaned, marks\n",
                "        \n",
                "        return text.strip(), 0.0\n",
                "    \n",
                "    @classmethod\n",
                "    def detect_question_type(cls, text: str) -> str:\n",
                "        \"\"\"Detect type of question.\"\"\"\n",
                "        text_lower = text.lower()\n",
                "        \n",
                "        if any(kw in text_lower for kw in ['choose', 'select', 'option', 'a)', 'b)', 'c)', 'd)']):\n",
                "            return 'mcq'\n",
                "        elif any(kw in text_lower for kw in ['fill', 'blank', '____', '___']):\n",
                "            return 'fill_blank'\n",
                "        elif any(kw in text_lower for kw in ['true', 'false', 't/f']):\n",
                "            return 'true_false'\n",
                "        elif any(kw in text_lower for kw in ['explain', 'describe', 'discuss', 'elaborate', 'derive']):\n",
                "            return 'long_answer'\n",
                "        elif any(kw in text_lower for kw in ['define', 'state', 'what is', 'name', 'list']):\n",
                "            return 'short_answer'\n",
                "        elif any(kw in text_lower for kw in ['calculate', 'solve', 'find', 'compute']):\n",
                "            return 'numerical'\n",
                "        else:\n",
                "            return 'short_answer'\n",
                "    \n",
                "    @classmethod\n",
                "    def extract_questions(cls, text: str) -> List[Question]:\n",
                "        \"\"\"\n",
                "        Extract all questions from paper text.\n",
                "        \"\"\"\n",
                "        questions = []\n",
                "        current_section = None\n",
                "        \n",
                "        # Split into lines for processing\n",
                "        lines = text.split('\\n')\n",
                "        current_question_lines = []\n",
                "        current_number = None\n",
                "        \n",
                "        for line in lines:\n",
                "            line = line.strip()\n",
                "            if not line:\n",
                "                continue\n",
                "            \n",
                "            # Check for section header\n",
                "            for pattern in cls.SECTION_PATTERNS:\n",
                "                match = re.search(pattern, line, re.IGNORECASE)\n",
                "                if match:\n",
                "                    current_section = f\"Section {match.group(1)}\"\n",
                "                    break\n",
                "            \n",
                "            # Check for question start\n",
                "            question_match = re.match(r'^\\s*(\\d+)[.)]\\s+(.+)', line)\n",
                "            q_match = re.match(r'^\\s*[Qq]\\.?\\s*(\\d+)[.)]?\\s+(.+)', line)\n",
                "            \n",
                "            match = question_match or q_match\n",
                "            \n",
                "            if match:\n",
                "                # Save previous question\n",
                "                if current_number and current_question_lines:\n",
                "                    full_text = ' '.join(current_question_lines)\n",
                "                    clean_text, marks = cls.extract_marks(full_text)\n",
                "                    q_type = cls.detect_question_type(clean_text)\n",
                "                    \n",
                "                    questions.append(Question(\n",
                "                        number=current_number,\n",
                "                        text=clean_text,\n",
                "                        marks=marks,\n",
                "                        section=current_section,\n",
                "                        question_type=q_type\n",
                "                    ))\n",
                "                \n",
                "                current_number = match.group(1)\n",
                "                current_question_lines = [match.group(2)]\n",
                "            elif current_number:\n",
                "                # Continue current question\n",
                "                current_question_lines.append(line)\n",
                "        \n",
                "        # Don't forget the last question\n",
                "        if current_number and current_question_lines:\n",
                "            full_text = ' '.join(current_question_lines)\n",
                "            clean_text, marks = cls.extract_marks(full_text)\n",
                "            q_type = cls.detect_question_type(clean_text)\n",
                "            \n",
                "            questions.append(Question(\n",
                "                number=current_number,\n",
                "                text=clean_text,\n",
                "                marks=marks,\n",
                "                section=current_section,\n",
                "                question_type=q_type\n",
                "            ))\n",
                "        \n",
                "        return questions\n",
                "\n",
                "\n",
                "# Test\n",
                "test_paper = \"\"\"\n",
                "PHYSICS EXAM\n",
                "Total Marks: 50\n",
                "Time: 2 Hours\n",
                "\n",
                "Section A (Short Answer)\n",
                "\n",
                "1. State Newton's first law of motion. (2 marks)\n",
                "\n",
                "2. Define acceleration. Give its SI unit. (3 marks)\n",
                "\n",
                "3. What is the difference between mass and weight? (2 marks)\n",
                "\n",
                "Section B (Problems)\n",
                "\n",
                "4. Calculate the force required to accelerate a 5 kg object at 10 m/sÂ². (5 marks)\n",
                "\n",
                "5. Derive the equation vÂ² = uÂ² + 2as from first principles. (8 marks)\n",
                "\"\"\"\n",
                "\n",
                "questions = QuestionExtractor.extract_questions(test_paper)\n",
                "print(f\"\\nExtracted {len(questions)} questions:\\n\")\n",
                "for q in questions:\n",
                "    print(f\"  Q{q.number} [{q.section}] ({q.marks}m, {q.question_type}): {q.text[:50]}...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 6. Complete Paper Parser"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class QuestionPaperParser:\n",
                "    \"\"\"\n",
                "    Complete pipeline to parse question papers.\n",
                "    \"\"\"\n",
                "    \n",
                "    def __init__(self):\n",
                "        self.metadata_extractor = MetadataExtractor\n",
                "        self.question_extractor = QuestionExtractor\n",
                "    \n",
                "    def parse_file(self, file_path: str) -> QuestionPaper:\n",
                "        \"\"\"\n",
                "        Parse a question paper file.\n",
                "        \"\"\"\n",
                "        # Extract text\n",
                "        raw_text = extract_text(file_path)\n",
                "        return self.parse_text(raw_text)\n",
                "    \n",
                "    def parse_text(self, text: str) -> QuestionPaper:\n",
                "        \"\"\"\n",
                "        Parse question paper from raw text.\n",
                "        \"\"\"\n",
                "        # Extract metadata\n",
                "        title = self.metadata_extractor.extract_title(text)\n",
                "        subject = self.metadata_extractor.extract_subject(text)\n",
                "        total_marks = self.metadata_extractor.extract_total_marks(text)\n",
                "        time_limit = self.metadata_extractor.extract_time_limit(text)\n",
                "        \n",
                "        # Extract questions\n",
                "        questions = self.question_extractor.extract_questions(text)\n",
                "        \n",
                "        # Extract sections\n",
                "        sections = list(set(q.section for q in questions if q.section))\n",
                "        \n",
                "        # Calculate total marks if not found in text\n",
                "        if total_marks == 0:\n",
                "            total_marks = sum(q.marks for q in questions)\n",
                "        \n",
                "        # Extract instructions\n",
                "        instructions = self._extract_instructions(text)\n",
                "        \n",
                "        return QuestionPaper(\n",
                "            title=title,\n",
                "            subject=subject,\n",
                "            total_marks=total_marks,\n",
                "            time_limit_minutes=time_limit,\n",
                "            instructions=instructions,\n",
                "            sections=sorted(sections),\n",
                "            questions=questions,\n",
                "            raw_text=text\n",
                "        )\n",
                "    \n",
                "    def _extract_instructions(self, text: str) -> List[str]:\n",
                "        \"\"\"Extract instructions from paper.\"\"\"\n",
                "        instructions = []\n",
                "        lines = text.split('\\n')\n",
                "        \n",
                "        in_instructions = False\n",
                "        for line in lines:\n",
                "            line = line.strip()\n",
                "            \n",
                "            if 'instruction' in line.lower():\n",
                "                in_instructions = True\n",
                "                continue\n",
                "            \n",
                "            if in_instructions:\n",
                "                # Stop at section or question start\n",
                "                if re.match(r'^(Section|SECTION|\\d+[.)])', line):\n",
                "                    break\n",
                "                if line:\n",
                "                    instructions.append(line)\n",
                "        \n",
                "        return instructions[:5]  # Limit to 5 instructions\n",
                "    \n",
                "    def to_json(self, paper: QuestionPaper) -> str:\n",
                "        \"\"\"Export paper as JSON.\"\"\"\n",
                "        return json.dumps(paper.to_dict(), indent=2)\n",
                "\n",
                "\n",
                "# Test complete pipeline\n",
                "parser = QuestionPaperParser()\n",
                "paper = parser.parse_text(test_paper)\n",
                "\n",
                "print(\"=\"*60)\n",
                "print(\"PARSED QUESTION PAPER\")\n",
                "print(\"=\"*60)\n",
                "print(f\"Title: {paper.title}\")\n",
                "print(f\"Subject: {paper.subject}\")\n",
                "print(f\"Total Marks: {paper.total_marks}\")\n",
                "print(f\"Time: {paper.time_limit_minutes} minutes\")\n",
                "print(f\"Sections: {paper.sections}\")\n",
                "print(f\"Questions: {len(paper.questions)}\")\n",
                "print()\n",
                "print(\"Questions:\")\n",
                "for q in paper.questions:\n",
                "    print(f\"  {q.number}. [{q.marks}m] {q.text[:60]}...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 7. Answer Key Association"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def add_answer_key(paper: QuestionPaper, answer_key: Dict[str, dict]) -> QuestionPaper:\n",
                "    \"\"\"\n",
                "    Associate expected answers with questions.\n",
                "    \n",
                "    Args:\n",
                "        paper: Parsed question paper\n",
                "        answer_key: Dict mapping question number to {\"answer\": str, \"keywords\": list}\n",
                "    \n",
                "    Returns:\n",
                "        Updated paper with answers\n",
                "    \"\"\"\n",
                "    for question in paper.questions:\n",
                "        if question.number in answer_key:\n",
                "            key = answer_key[question.number]\n",
                "            question.expected_answer = key.get(\"answer\", \"\")\n",
                "            question.keywords = key.get(\"keywords\", [])\n",
                "    \n",
                "    return paper\n",
                "\n",
                "\n",
                "# Example\n",
                "answer_key = {\n",
                "    \"1\": {\n",
                "        \"answer\": \"Newton's first law states that an object at rest stays at rest, and an object in motion stays in motion, unless acted upon by an external force.\",\n",
                "        \"keywords\": [\"rest\", \"motion\", \"external force\", \"inertia\"]\n",
                "    },\n",
                "    \"2\": {\n",
                "        \"answer\": \"Acceleration is the rate of change of velocity with respect to time. SI unit is m/sÂ² (meters per second squared).\",\n",
                "        \"keywords\": [\"rate of change\", \"velocity\", \"time\", \"m/sÂ²\"]\n",
                "    },\n",
                "    \"4\": {\n",
                "        \"answer\": \"Using F = ma, F = 5 Ã— 10 = 50 N\",\n",
                "        \"keywords\": [\"F = ma\", \"50\", \"N\", \"newton\"]\n",
                "    }\n",
                "}\n",
                "\n",
                "paper_with_answers = add_answer_key(paper, answer_key)\n",
                "\n",
                "print(\"Questions with answers:\")\n",
                "for q in paper_with_answers.questions:\n",
                "    if q.expected_answer:\n",
                "        print(f\"\\nQ{q.number}: {q.text[:50]}...\")\n",
                "        print(f\"   Answer: {q.expected_answer[:80]}...\")\n",
                "        print(f\"   Keywords: {q.keywords}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 8. Export Module"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Export JSON for integration\n",
                "json_output = parser.to_json(paper_with_answers)\n",
                "print(\"JSON Output:\")\n",
                "print(json_output)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save module to utils\n",
                "PAPER_PARSER_MODULE = '''\n",
                "\"\"\"\n",
                "Question Paper Parser\n",
                "\n",
                "Extract questions, marks, sections from question papers.\n",
                "\"\"\"\n",
                "import re\n",
                "import json\n",
                "from typing import List, Dict, Optional, Tuple\n",
                "from dataclasses import dataclass, field, asdict\n",
                "\n",
                "@dataclass\n",
                "class Question:\n",
                "    number: str\n",
                "    text: str\n",
                "    marks: float\n",
                "    section: Optional[str] = None\n",
                "    question_type: str = \"short_answer\"\n",
                "    expected_answer: Optional[str] = None\n",
                "    keywords: List[str] = field(default_factory=list)\n",
                "\n",
                "@dataclass\n",
                "class QuestionPaper:\n",
                "    title: str\n",
                "    subject: str\n",
                "    total_marks: float\n",
                "    time_limit_minutes: int\n",
                "    instructions: List[str] = field(default_factory=list)\n",
                "    sections: List[str] = field(default_factory=list)\n",
                "    questions: List[Question] = field(default_factory=list)\n",
                "    \n",
                "    def to_dict(self) -> dict:\n",
                "        return {\n",
                "            \"title\": self.title, \"subject\": self.subject,\n",
                "            \"total_marks\": self.total_marks, \"time_limit_minutes\": self.time_limit_minutes,\n",
                "            \"sections\": self.sections, \"questions\": [asdict(q) for q in self.questions]\n",
                "        }\n",
                "\n",
                "class QuestionPaperParser:\n",
                "    MARK_PATTERNS = [r\"\\\\((\\\\d+(?:\\\\.\\\\d+)?)\\\\s*(?:marks?|m)\\\\)\", r\"(\\\\d+)\\\\s*marks?$\"]\n",
                "    \n",
                "    def parse_text(self, text: str) -> QuestionPaper:\n",
                "        title = self._extract_title(text)\n",
                "        subject = self._detect_subject(text)\n",
                "        total_marks = self._extract_total_marks(text)\n",
                "        time_limit = self._extract_time(text)\n",
                "        questions = self._extract_questions(text)\n",
                "        sections = list(set(q.section for q in questions if q.section))\n",
                "        if total_marks == 0: total_marks = sum(q.marks for q in questions)\n",
                "        return QuestionPaper(title, subject, total_marks, time_limit, [], sections, questions)\n",
                "    \n",
                "    def _extract_title(self, text): \n",
                "        for line in text.split(\"\\\\n\")[:5]:\n",
                "            if len(line.strip()) > 10: return line.strip()[:100]\n",
                "        return \"Question Paper\"\n",
                "    \n",
                "    def _detect_subject(self, text):\n",
                "        for subj in [\"physics\", \"chemistry\", \"math\", \"biology\", \"english\"]:\n",
                "            if subj in text.lower(): return subj.capitalize()\n",
                "        return \"General\"\n",
                "    \n",
                "    def _extract_total_marks(self, text):\n",
                "        m = re.search(r\"(?:total|max)\\\\s*marks?\\\\s*[:\\\\-]?\\\\s*(\\\\d+)\", text.lower())\n",
                "        return float(m.group(1)) if m else 0\n",
                "    \n",
                "    def _extract_time(self, text):\n",
                "        m = re.search(r\"time\\\\s*[:\\\\-]?\\\\s*(\\\\d+)\\\\s*(?:hours?|hrs?)\", text.lower())\n",
                "        return int(m.group(1)) * 60 if m else 0\n",
                "    \n",
                "    def _extract_questions(self, text) -> List[Question]:\n",
                "        questions, section = [], None\n",
                "        for line in text.split(\"\\\\n\"):\n",
                "            sec = re.search(r\"Section\\\\s+([A-Z])\", line, re.I)\n",
                "            if sec: section = f\"Section {sec.group(1)}\"\n",
                "            m = re.match(r\"^\\\\s*(\\\\d+)[.)]\\\\s+(.+)\", line)\n",
                "            if m:\n",
                "                txt, marks = self._extract_marks(m.group(2))\n",
                "                questions.append(Question(m.group(1), txt, marks, section))\n",
                "        return questions\n",
                "    \n",
                "    def _extract_marks(self, text):\n",
                "        for p in self.MARK_PATTERNS:\n",
                "            m = re.search(p, text, re.I)\n",
                "            if m: return re.sub(p, \"\", text).strip(), float(m.group(1))\n",
                "        return text.strip(), 0.0\n",
                "'''\n",
                "\n",
                "output_path = Path(\"../utils/paper_parser.py\")\n",
                "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
                "output_path.write_text(PAPER_PARSER_MODULE)\n",
                "print(f\"âœ… Saved to {output_path.resolve()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Summary\n",
                "\n",
                "| Component | Purpose |\n",
                "|-----------|--------|\n",
                "| `extract_text()` | PDF/Image â†’ Text |\n",
                "| `MetadataExtractor` | Title, marks, time |\n",
                "| `QuestionExtractor` | Questions, sections |\n",
                "| `QuestionPaperParser` | Complete pipeline |\n",
                "| `add_answer_key()` | Link expected answers |\n",
                "\n",
                "**Output:** JSON with structured question paper data."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}