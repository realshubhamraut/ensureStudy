{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üõ°Ô∏è Proctoring Model Training - Overview\n",
                "\n",
                "This notebook provides a comprehensive guide for training AI proctoring models for the EnsureStudy platform.\n",
                "\n",
                "## Training Pipeline\n",
                "\n",
                "The proctoring system uses a two-stage approach:\n",
                "\n",
                "1. **Feature Extraction** - Extract features from webcam frames\n",
                "2. **Model Training** - Train classifiers on extracted features\n",
                "\n",
                "### Models to Train\n",
                "\n",
                "| Model | Purpose | Notebook |\n",
                "|-------|---------|----------|\n",
                "| Static Classifier | Frame-by-frame cheating detection | `proctor_static_model.ipynb` |\n",
                "| Temporal LSTM | Behavior pattern analysis over time | `proctor_temporal_model.ipynb` |\n",
                "\n",
                "### Required Data\n",
                "\n",
                "Training data should be in the format:\n",
                "- `Train/` and `Test/` directories\n",
                "- Each containing video subdirectories\n",
                "- With `front/` and `side/` camera frames\n",
                "- Labeled as `cheating_frames/` or `not_cheating_frames/`\n",
                "\n",
                "### Model Outputs\n",
                "\n",
                "Trained models are saved to `ml/models/proctoring/`:\n",
                "- `static_model.pkl` - LightGBM/XGBoost classifier\n",
                "- `static_scaler.pkl` - Feature scaler\n",
                "- `temporal_lstm.pt` - PyTorch LSTM model\n",
                "- `model_metadata.json` - Feature names and hyperparameters"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Verify required dependencies\n",
                "import sys\n",
                "import importlib\n",
                "\n",
                "required = [\n",
                "    'numpy', 'pandas', 'torch', 'sklearn', 'joblib'\n",
                "]\n",
                "\n",
                "missing = []\n",
                "for pkg in required:\n",
                "    try:\n",
                "        importlib.import_module(pkg)\n",
                "        print(f\"‚úÖ {pkg}\")\n",
                "    except ImportError:\n",
                "        missing.append(pkg)\n",
                "        print(f\"‚ùå {pkg}\")\n",
                "\n",
                "if missing:\n",
                "    print(f\"\\nInstall missing packages: pip install {' '.join(missing)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Directory Structure\n",
                "\n",
                "```\n",
                "ml/\n",
                "‚îú‚îÄ‚îÄ models/\n",
                "‚îÇ   ‚îî‚îÄ‚îÄ proctoring/           # Saved models go here\n",
                "‚îÇ       ‚îú‚îÄ‚îÄ static_model.pkl\n",
                "‚îÇ       ‚îú‚îÄ‚îÄ static_scaler.pkl\n",
                "‚îÇ       ‚îú‚îÄ‚îÄ temporal_lstm.pt\n",
                "‚îÇ       ‚îî‚îÄ‚îÄ model_metadata.json\n",
                "‚îú‚îÄ‚îÄ data/\n",
                "‚îÇ   ‚îî‚îÄ‚îÄ proctoring/           # Training data\n",
                "‚îÇ       ‚îú‚îÄ‚îÄ train.csv\n",
                "‚îÇ       ‚îî‚îÄ‚îÄ test.csv\n",
                "‚îî‚îÄ‚îÄ notebooks/\n",
                "    ‚îú‚îÄ‚îÄ proctor_training_overview.ipynb  # This notebook\n",
                "    ‚îú‚îÄ‚îÄ proctor_feature_extraction.ipynb\n",
                "    ‚îú‚îÄ‚îÄ proctor_static_model.ipynb\n",
                "    ‚îî‚îÄ‚îÄ proctor_temporal_model.ipynb\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create required directories\n",
                "import os\n",
                "\n",
                "base_path = os.path.dirname(os.getcwd())  # ml/ directory\n",
                "directories = [\n",
                "    os.path.join(base_path, 'models', 'proctoring'),\n",
                "    os.path.join(base_path, 'data', 'proctoring')\n",
                "]\n",
                "\n",
                "for dir_path in directories:\n",
                "    os.makedirs(dir_path, exist_ok=True)\n",
                "    print(f\"‚úÖ Created: {dir_path}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Next Steps\n",
                "\n",
                "1. **Prepare Data**: See `proctor_feature_extraction.ipynb`\n",
                "2. **Train Static Model**: See `proctor_static_model.ipynb`\n",
                "3. **Train Temporal Model**: See `proctor_temporal_model.ipynb`\n",
                "4. **Deploy Models**: Copy to `backend/ai-service/app/proctor/models/weights/`"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}