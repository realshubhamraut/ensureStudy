{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“Š Student Performance Prediction Pipeline\n",
    "\n",
    "Predict student exam scores using ML models.\n",
    "\n",
    "**Kaggle Datasets:**\n",
    "- [Student Performance](https://www.kaggle.com/datasets/spscientist/students-performance-in-exams)\n",
    "- [Open University (OULAD)](https://www.kaggle.com/datasets/rocki37/open-university-learning-analytics-dataset)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "print('Setup complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate/Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_data(n_samples=1000):\n",
    "    np.random.seed(42)\n",
    "    data = {\n",
    "        'study_hours': np.random.uniform(1, 10, n_samples),\n",
    "        'attendance_rate': np.random.uniform(50, 100, n_samples),\n",
    "        'previous_score': np.random.uniform(30, 100, n_samples),\n",
    "        'parental_education': np.random.choice(['high_school', 'bachelors', 'masters'], n_samples),\n",
    "        'internet_access': np.random.choice([0, 1], n_samples),\n",
    "        'extracurricular': np.random.choice([0, 1], n_samples),\n",
    "        'sleep_hours': np.random.uniform(4, 10, n_samples),\n",
    "        'screen_time': np.random.uniform(1, 8, n_samples),\n",
    "    }\n",
    "    target = (data['study_hours'] * 5 + data['attendance_rate'] * 0.3 +\n",
    "              data['previous_score'] * 0.4 + data['internet_access'] * 5 +\n",
    "              data['sleep_hours'] * 2 - data['screen_time'] * 1.5 + np.random.normal(0, 5, n_samples))\n",
    "    data['final_score'] = np.clip(target, 0, 100)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "df = generate_synthetic_data()\n",
    "print(f'Dataset: {df.shape}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=== Correlation with Final Score ===')\n",
    "for col in df.select_dtypes(include=[np.number]).columns:\n",
    "    if col != 'final_score':\n",
    "        print(f'{col}: {df[col].corr(df[\"final_score\"]):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['final_score'])\n",
    "y = df['final_score']\n",
    "\n",
    "# Encode categorical\n",
    "le = LabelEncoder()\n",
    "X['parental_education'] = le.fit_transform(X['parental_education'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f'Train: {X_train_scaled.shape}, Test: {X_test_scaled.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge': Ridge(alpha=1.0),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "best_model, best_r2 = None, -np.inf\n",
    "\n",
    "print('=== Model Results ===')\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    print(f'{name}: RÂ²={r2:.3f}, RMSE={rmse:.2f}')\n",
    "    if r2 > best_r2:\n",
    "        best_r2, best_model = r2, (name, model)\n",
    "\n",
    "print(f'\\nBest: {best_model[0]} (RÂ²={best_r2:.3f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(best_model[1], '../models/student_performance.joblib')\n",
    "joblib.dump(scaler, '../models/student_performance_scaler.joblib')\n",
    "print('Model saved!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Demo Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = [[7, 85, 75, 1, 1, 1, 7, 3]]  # study, attend, prev, parent_edu, internet, extra, sleep, screen\n",
    "sample_scaled = scaler.transform(sample)\n",
    "pred = best_model[1].predict(sample_scaled)[0]\n",
    "print(f'Predicted Score: {pred:.1f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},
  "language_info": {"name": "python", "version": "3.10.0"}
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
