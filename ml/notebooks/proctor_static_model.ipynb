{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸŽ¯ Static Proctoring Model Training\n",
                "\n",
                "Train a frame-by-frame cheating detection model using LightGBM or XGBoost.\n",
                "\n",
                "**Based on**: AutoOEP/Static/static_trainer.py\n",
                "\n",
                "## Features Used\n",
                "- Face verification status\n",
                "- Eye gaze direction & iris position\n",
                "- Head pose (x, y, z rotation)\n",
                "- Mouth activity zone\n",
                "- Prohibited objects detected (phone, earpiece, etc.)\n",
                "- Hand distance from camera"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import joblib\n",
                "import json\n",
                "from datetime import datetime\n",
                "\n",
                "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.metrics import (\n",
                "    accuracy_score, precision_score, recall_score, f1_score,\n",
                "    roc_auc_score, confusion_matrix, classification_report\n",
                ")\n",
                "\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "# Suppress warnings\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "print(\"âœ… Libraries imported\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Paths\n",
                "BASE_PATH = os.path.dirname(os.getcwd())  # ml/ directory\n",
                "DATA_PATH = os.path.join(BASE_PATH, 'data', 'proctoring')\n",
                "MODEL_PATH = os.path.join(BASE_PATH, 'models', 'proctoring')\n",
                "\n",
                "# Create directories\n",
                "os.makedirs(MODEL_PATH, exist_ok=True)\n",
                "\n",
                "# Training settings\n",
                "CONFIG = {\n",
                "    'random_state': 42,\n",
                "    'test_size': 0.2,\n",
                "    'use_scaling': True,\n",
                "    'model_type': 'lightgbm',  # 'lightgbm', 'xgboost', or 'ensemble'\n",
                "    'threshold': 0.5,\n",
                "}\n",
                "\n",
                "# Feature columns (from AutoOEP)\n",
                "FEATURE_COLUMNS = [\n",
                "    'verification_result', 'num_faces', 'iris_pos', 'iris_ratio',\n",
                "    'mouth_zone', 'mouth_area', 'x_rotation', 'y_rotation', 'z_rotation',\n",
                "    'radial_distance', 'gaze_direction', 'gaze_zone',\n",
                "    'watch', 'headphone', 'closedbook', 'earpiece', 'cell phone',\n",
                "    'openbook', 'chits', 'sheet', 'H-Distance', 'F-Distance'\n",
                "]\n",
                "\n",
                "TARGET_COLUMN = 'is_cheating'\n",
                "\n",
                "print(f\"Model will be saved to: {MODEL_PATH}\")\n",
                "print(f\"Using {len(FEATURE_COLUMNS)} features\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Load Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_data(data_path, feature_columns, target_column):\n",
                "    \"\"\"Load and prepare training data from CSV files.\"\"\"\n",
                "    \n",
                "    # Look for CSV files\n",
                "    csv_files = [f for f in os.listdir(data_path) if f.endswith('.csv')]\n",
                "    \n",
                "    if not csv_files:\n",
                "        print(f\"âŒ No CSV files found in {data_path}\")\n",
                "        print(\"Please run feature extraction first or provide training data.\")\n",
                "        return None, None\n",
                "    \n",
                "    # Combine all CSVs\n",
                "    dfs = []\n",
                "    for f in csv_files:\n",
                "        df = pd.read_csv(os.path.join(data_path, f))\n",
                "        dfs.append(df)\n",
                "        print(f\"  Loaded {f}: {len(df)} rows\")\n",
                "    \n",
                "    combined_df = pd.concat(dfs, ignore_index=True)\n",
                "    print(f\"\\nTotal rows: {len(combined_df)}\")\n",
                "    \n",
                "    # Check for required columns\n",
                "    available_features = [c for c in feature_columns if c in combined_df.columns]\n",
                "    missing_features = [c for c in feature_columns if c not in combined_df.columns]\n",
                "    \n",
                "    if missing_features:\n",
                "        print(f\"âš ï¸ Missing features: {missing_features}\")\n",
                "    \n",
                "    if target_column not in combined_df.columns:\n",
                "        print(f\"âŒ Target column '{target_column}' not found!\")\n",
                "        return None, None\n",
                "    \n",
                "    # Prepare X and y\n",
                "    X = combined_df[available_features].copy()\n",
                "    y = combined_df[target_column].copy()\n",
                "    \n",
                "    # Handle missing values\n",
                "    X = X.fillna(0)\n",
                "    \n",
                "    print(f\"\\nFeatures shape: {X.shape}\")\n",
                "    print(f\"Class distribution:\\n{y.value_counts()}\")\n",
                "    \n",
                "    return X, y\n",
                "\n",
                "# Load data\n",
                "X, y = load_data(DATA_PATH, FEATURE_COLUMNS, TARGET_COLUMN)\n",
                "\n",
                "if X is not None:\n",
                "    print(\"\\nâœ… Data loaded successfully\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Train/Test Split & Preprocessing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if X is not None:\n",
                "    # Split data\n",
                "    X_train, X_test, y_train, y_test = train_test_split(\n",
                "        X, y,\n",
                "        test_size=CONFIG['test_size'],\n",
                "        random_state=CONFIG['random_state'],\n",
                "        stratify=y\n",
                "    )\n",
                "    \n",
                "    print(f\"Training set: {len(X_train)} samples\")\n",
                "    print(f\"Test set: {len(X_test)} samples\")\n",
                "    \n",
                "    # Scale features\n",
                "    scaler = None\n",
                "    if CONFIG['use_scaling']:\n",
                "        scaler = StandardScaler()\n",
                "        X_train_scaled = scaler.fit_transform(X_train)\n",
                "        X_test_scaled = scaler.transform(X_test)\n",
                "        print(\"âœ… Features scaled\")\n",
                "    else:\n",
                "        X_train_scaled = X_train.values\n",
                "        X_test_scaled = X_test.values"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Train Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def train_lightgbm(X_train, y_train, X_val, y_val):\n",
                "    \"\"\"Train a LightGBM classifier.\"\"\"\n",
                "    try:\n",
                "        import lightgbm as lgb\n",
                "    except ImportError:\n",
                "        print(\"âŒ LightGBM not installed. Run: pip install lightgbm\")\n",
                "        return None\n",
                "    \n",
                "    params = {\n",
                "        'objective': 'binary',\n",
                "        'metric': 'auc',\n",
                "        'boosting_type': 'gbdt',\n",
                "        'num_leaves': 31,\n",
                "        'learning_rate': 0.05,\n",
                "        'feature_fraction': 0.9,\n",
                "        'bagging_fraction': 0.8,\n",
                "        'bagging_freq': 5,\n",
                "        'verbose': -1,\n",
                "        'random_state': CONFIG['random_state']\n",
                "    }\n",
                "    \n",
                "    train_data = lgb.Dataset(X_train, label=y_train)\n",
                "    val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n",
                "    \n",
                "    model = lgb.train(\n",
                "        params,\n",
                "        train_data,\n",
                "        num_boost_round=500,\n",
                "        valid_sets=[train_data, val_data],\n",
                "        callbacks=[\n",
                "            lgb.early_stopping(stopping_rounds=50),\n",
                "            lgb.log_evaluation(period=100)\n",
                "        ]\n",
                "    )\n",
                "    \n",
                "    return model\n",
                "\n",
                "\n",
                "def train_xgboost(X_train, y_train, X_val, y_val):\n",
                "    \"\"\"Train an XGBoost classifier.\"\"\"\n",
                "    try:\n",
                "        import xgboost as xgb\n",
                "    except ImportError:\n",
                "        print(\"âŒ XGBoost not installed. Run: pip install xgboost\")\n",
                "        return None\n",
                "    \n",
                "    model = xgb.XGBClassifier(\n",
                "        objective='binary:logistic',\n",
                "        n_estimators=500,\n",
                "        learning_rate=0.05,\n",
                "        max_depth=6,\n",
                "        early_stopping_rounds=50,\n",
                "        random_state=CONFIG['random_state']\n",
                "    )\n",
                "    \n",
                "    model.fit(\n",
                "        X_train, y_train,\n",
                "        eval_set=[(X_val, y_val)],\n",
                "        verbose=100\n",
                "    )\n",
                "    \n",
                "    return model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if X is not None:\n",
                "    print(f\"Training {CONFIG['model_type'].upper()} model...\\n\")\n",
                "    \n",
                "    if CONFIG['model_type'] == 'lightgbm':\n",
                "        model = train_lightgbm(X_train_scaled, y_train, X_test_scaled, y_test)\n",
                "    elif CONFIG['model_type'] == 'xgboost':\n",
                "        model = train_xgboost(X_train_scaled, y_train, X_test_scaled, y_test)\n",
                "    else:\n",
                "        print(f\"Unknown model type: {CONFIG['model_type']}\")\n",
                "        model = None\n",
                "    \n",
                "    if model:\n",
                "        print(\"\\nâœ… Model trained successfully\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Evaluate Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def evaluate_model(model, X_test, y_test, threshold=0.5, model_type='lightgbm'):\n",
                "    \"\"\"Evaluate model and print metrics.\"\"\"\n",
                "    \n",
                "    # Get predictions\n",
                "    if model_type == 'lightgbm':\n",
                "        y_proba = model.predict(X_test)\n",
                "    else:\n",
                "        y_proba = model.predict_proba(X_test)[:, 1]\n",
                "    \n",
                "    y_pred = (y_proba >= threshold).astype(int)\n",
                "    \n",
                "    # Metrics\n",
                "    metrics = {\n",
                "        'accuracy': accuracy_score(y_test, y_pred),\n",
                "        'precision': precision_score(y_test, y_pred),\n",
                "        'recall': recall_score(y_test, y_pred),\n",
                "        'f1': f1_score(y_test, y_pred),\n",
                "        'auc_roc': roc_auc_score(y_test, y_proba)\n",
                "    }\n",
                "    \n",
                "    print(\"=\" * 50)\n",
                "    print(\"MODEL EVALUATION RESULTS\")\n",
                "    print(\"=\" * 50)\n",
                "    for name, value in metrics.items():\n",
                "        print(f\"{name.upper():15}: {value:.4f}\")\n",
                "    \n",
                "    print(\"\\nClassification Report:\")\n",
                "    print(classification_report(y_test, y_pred, target_names=['Not Cheating', 'Cheating']))\n",
                "    \n",
                "    # Confusion Matrix\n",
                "    cm = confusion_matrix(y_test, y_pred)\n",
                "    plt.figure(figsize=(8, 6))\n",
                "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
                "                xticklabels=['Not Cheating', 'Cheating'],\n",
                "                yticklabels=['Not Cheating', 'Cheating'])\n",
                "    plt.xlabel('Predicted')\n",
                "    plt.ylabel('Actual')\n",
                "    plt.title('Confusion Matrix')\n",
                "    plt.show()\n",
                "    \n",
                "    return metrics, y_proba\n",
                "\n",
                "if model is not None:\n",
                "    metrics, y_proba = evaluate_model(\n",
                "        model, X_test_scaled, y_test,\n",
                "        threshold=CONFIG['threshold'],\n",
                "        model_type=CONFIG['model_type']\n",
                "    )"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Save Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def save_model(model, scaler, feature_names, config, metrics, model_path):\n",
                "    \"\"\"Save model, scaler, and metadata.\"\"\"\n",
                "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
                "    \n",
                "    # Save model\n",
                "    model_file = os.path.join(model_path, 'static_model.pkl')\n",
                "    if config['model_type'] == 'lightgbm':\n",
                "        model.save_model(model_file.replace('.pkl', '.txt'))\n",
                "    else:\n",
                "        joblib.dump(model, model_file)\n",
                "    print(f\"âœ… Model saved: {model_file}\")\n",
                "    \n",
                "    # Save scaler\n",
                "    if scaler is not None:\n",
                "        scaler_file = os.path.join(model_path, 'static_scaler.pkl')\n",
                "        joblib.dump(scaler, scaler_file)\n",
                "        print(f\"âœ… Scaler saved: {scaler_file}\")\n",
                "    \n",
                "    # Save metadata\n",
                "    metadata = {\n",
                "        'model_type': config['model_type'],\n",
                "        'feature_names': feature_names,\n",
                "        'threshold': config['threshold'],\n",
                "        'training_date': timestamp,\n",
                "        'metrics': metrics\n",
                "    }\n",
                "    \n",
                "    metadata_file = os.path.join(model_path, 'static_metadata.json')\n",
                "    with open(metadata_file, 'w') as f:\n",
                "        json.dump(metadata, f, indent=2)\n",
                "    print(f\"âœ… Metadata saved: {metadata_file}\")\n",
                "\n",
                "if model is not None:\n",
                "    save_model(model, scaler, list(X.columns), CONFIG, metrics, MODEL_PATH)\n",
                "    print(\"\\nðŸŽ‰ Training complete! Models saved.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Feature Importance"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if model is not None:\n",
                "    # Get feature importance\n",
                "    if CONFIG['model_type'] == 'lightgbm':\n",
                "        importance = model.feature_importance(importance_type='gain')\n",
                "    else:\n",
                "        importance = model.feature_importances_\n",
                "    \n",
                "    # Create dataframe\n",
                "    feature_importance = pd.DataFrame({\n",
                "        'feature': list(X.columns),\n",
                "        'importance': importance\n",
                "    }).sort_values('importance', ascending=False)\n",
                "    \n",
                "    # Plot\n",
                "    plt.figure(figsize=(10, 8))\n",
                "    sns.barplot(data=feature_importance.head(15), x='importance', y='feature')\n",
                "    plt.title('Top 15 Feature Importances')\n",
                "    plt.xlabel('Importance')\n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "    \n",
                "    print(\"\\nTop 10 Features:\")\n",
                "    print(feature_importance.head(10).to_string(index=False))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.14.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
