# ============================================================================
# ensureStudy Production Docker Compose
# ============================================================================
# Usage:
#   docker-compose -f docker-compose.prod.yml up -d
#
# Prerequisites:
#   - Set up .env.production with your AWS/RDS credentials
#   - Build images: docker-compose -f docker-compose.prod.yml build
# ============================================================================

version: '3.8'

services:
  # ==========================================================================
  # Core API Service (Flask + Gunicorn)
  # ==========================================================================
  core-api:
    build:
      context: ./backend/core-service
      dockerfile: Dockerfile.prod
    container_name: ensurestudy-core-api
    restart: unless-stopped
    ports:
      - "8000:8000"
    environment:
      # Database (use RDS in production)
      DATABASE_URL: ${DATABASE_URL}

      # JWT Secret (generate a strong random string)
      JWT_SECRET: ${JWT_SECRET}

      # Storage configuration
      STORAGE_PROVIDER: ${STORAGE_PROVIDER:-local}
      AWS_S3_BUCKET: ${AWS_S3_BUCKET:-ensurestudy-files}
      AWS_REGION: ${AWS_REGION:-ap-south-1}
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}

      # Service URLs
      AI_SERVICE_URL: http://ai-service:8001
      CORE_SERVICE_URL: http://core-api:8000

      # Frontend URL (for CORS)
      FRONTEND_URL: ${FRONTEND_URL:-https://yourdomain.com}
    volumes:
      # Local storage fallback (remove if using S3 only)
      - uploads_data:/app/uploads
      - recordings_data:/app/recordings
    depends_on:
      - redis
      - mongodb
    networks:
      - ensurestudy-network
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8000/health" ]
      interval: 30s
      timeout: 10s
      retries: 3

  # ==========================================================================
  # AI Service (FastAPI + Whisper)
  # ==========================================================================
  ai-service:
    build:
      context: ./backend/ai-service
      dockerfile: Dockerfile.prod
      args:
        # Choose Whisper model size: tiny, base, small, medium, large
        # smaller = faster but less accurate
        WHISPER_MODEL: ${WHISPER_MODEL:-small}
    container_name: ensurestudy-ai-service
    restart: unless-stopped
    ports:
      - "8001:8001"
    environment:
      # Whisper configuration
      WHISPER_MODEL: ${WHISPER_MODEL:-small}

      # Service URLs
      CORE_SERVICE_URL: http://core-api:8000

      # MongoDB for transcripts
      MONGO_URI: mongodb://mongodb:27017
      MONGO_DB: ensure_study_meetings

      # Qdrant for vector search
      QDRANT_HOST: qdrant
      QDRANT_PORT: 6333

      # OpenAI API (optional, for GPT-4 summaries)
      OPENAI_API_KEY: ${OPENAI_API_KEY:-}

      # Google Gemini (optional)
      GOOGLE_API_KEY: ${GOOGLE_API_KEY:-}

      # Storage for accessing recordings
      STORAGE_PROVIDER: ${STORAGE_PROVIDER:-local}
      AWS_S3_BUCKET: ${AWS_S3_BUCKET:-ensurestudy-files}
      AWS_REGION: ${AWS_REGION:-ap-south-1}
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
    volumes:
      # Whisper model cache (persists downloaded models)
      - whisper_cache:/root/.cache/whisper
      # Recordings (if using local storage)
      - recordings_data:/app/recordings:ro
    depends_on:
      - mongodb
      - qdrant
      - redis
    networks:
      - ensurestudy-network
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8001/health" ]
      interval: 30s
      timeout: 10s
      retries: 3

  # ==========================================================================
  # MongoDB (for transcripts and sessions)
  # ==========================================================================
  mongodb:
    image: mongo:7
    container_name: ensurestudy-mongodb
    restart: unless-stopped
    ports:
      - "27017:27017"
    environment:
      MONGO_INITDB_ROOT_USERNAME: ${MONGO_USER:-admin}
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_PASSWORD:-mongopassword}
    volumes:
      - mongodb_data:/data/db
    networks:
      - ensurestudy-network

  # ==========================================================================
  # Redis (for caching and session management)
  # ==========================================================================
  redis:
    image: redis:7-alpine
    container_name: ensurestudy-redis
    restart: unless-stopped
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      - ensurestudy-network

  # ==========================================================================
  # Qdrant (for vector search / RAG)
  # ==========================================================================
  qdrant:
    image: qdrant/qdrant:latest
    container_name: ensurestudy-qdrant
    restart: unless-stopped
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - qdrant_data:/qdrant/storage
    networks:
      - ensurestudy-network
  # ==========================================================================
  # Nginx Reverse Proxy (optional, for SSL termination)
  # ==========================================================================
  # Uncomment if you want to handle SSL at the container level
  # nginx:
  #   image: nginx:alpine
  #   container_name: ensurestudy-nginx
  #   restart: unless-stopped
  #   ports:
  #     - "80:80"
  #     - "443:443"
  #   volumes:
  #     - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
  #     - ./nginx/ssl:/etc/nginx/ssl:ro
  #   depends_on:
  #     - core-api
  #     - ai-service
  #   networks:
  #     - ensurestudy-network

  # ==========================================================================
  # Volumes
  # ==========================================================================
volumes:
  mongodb_data:
    driver: local
  redis_data:
    driver: local
  qdrant_data:
    driver: local
  whisper_cache:
    driver: local
  uploads_data:
    driver: local
  recordings_data:
    driver: local

# ==========================================================================
# Networks
# ==========================================================================
networks:
  ensurestudy-network:
    driver: bridge
